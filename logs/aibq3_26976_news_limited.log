2024-10-19 21:39:56,531 - INFO - Formatted articles for 2024-08-08T14:30:00Z:
Here are the relevant news articles:

**From Sci-Fi To State Law: California's Plan To Prevent AI Catastrophe**
California's 'Safe and Secure Innovation for Frontier Artificial Intelligence Models Act' (SB-1047) aims to prevent AI catastrophe by requiring companies behind large AI models to implement safety measures. Critics argue that the bill's focus on existential threats could limit research and development for non-threatening AI uses. The bill defines 'safety incidents' as harms leading to 'mass casualties or at least $500 million of damage', and requires AI creators to implement shutdown capabilities and policies. Supporters, including AI experts Geoffrey Hinton and Yoshua Bengio, believe the bill is a necessary precaution against potential catastrophic AI risks. Critics, including tech policy expert Nirit Weiss-Blatt and AI community voice Daniel Jeffries, argue that the bill is based on science fiction fears and could harm technological advancement.
Original language: en
Publish date: July 29, 2024 11:00 PM
Source:[Slashdot](https://yro.slashdot.org/story/24/07/29/2237231/from-sci-fi-to-state-law-californias-plan-to-prevent-ai-catastrophe)

**Senate Bill 1047 will crush AI innovation in California**
California's Senate Bill 1047, the Safe and Secure Frontier Artificial Intelligence Act, threatens to crush AI innovation in the state. The bill imposes liability on AI developers for what users do with their products, making it difficult for developers to certify their products and potentially chilling major investment in AI technologies. The bill also creates a new regulatory body, the Frontier Model Division, which would be funded by fees and fines, creating an incentive to levy heavy fines and find creative applications of the law. The bill raises constitutional concerns, as AI development is interstate commerce and states do not have the right to regulate it. The author argues that Congress should pass a preemption bill to prevent bad state laws like this from stopping AI innovation.
Original language: en
Publish date: July 10, 2024 03:29 PM
Source:[Long Beach Press-Telegram](https://www.presstelegram.com/2024/07/10/senate-bill-1047-will-crush-ai-innovation-in-california)

**AI safety bill SB 1047 passes committee vote in Sacramento**
The California state Senate passed the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047) in May 2024, requiring AI companies to test the safety of their programs and create security measures to prevent manipulation or rogue behavior. The bill, introduced by Sen. Scott Wiener, aims to ensure AI innovation does not compromise safety. However, companies like Meta and Google have pushed back, arguing the law should target those who exploit AI, not developers. The bill will go to the Assembly Appropriations Committee in August and, if passed, to a full floor vote later that month.
Original language: en
Publish date: July 02, 2024 09:12 PM
Source:[The Business Journals](https://www.bizjournals.com/sanfrancisco/news/2024/07/02/ai-regulation-sb-1047-committee.html)

**SB 1047 up for vote in Sacramento today**
The Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047) is up for a vote in Sacramento today. The bill was first introduced in February 2024 and passed in May by the California State Senate.
Original language: en
Publish date: July 02, 2024 03:45 PM
Source:[World News Network](https://article.wn.com/view/2024/07/02/SB_1047_up_for_vote_in_Sacramento_today)

**Proposed law to control powerful AI models will destroy California's nascent industry**
A proposed bill in the California State Senate, SB 1047, threatens to stifle the state's AI industry with draconian regulations and government overreach. The bill, titled 'Safe and Secure Innovation for Frontier Artificial Intelligence Models Act', would impose strict restrictions and oversight on companies developing cutting-edge AI models, potentially killing innovation, concentrating power in the hands of tech giants, and costing thousands of jobs. The bill's vague language gives too much power to a new government bureaucracy, making it difficult for startups and researchers to innovate, and contains no concrete provisions to protect consumers.
Original language: en
Publish date: June 11, 2024 04:39 PM
Source:[RocketNews](https://www.rocketnews.com/2024/06/proposed-law-to-control-powerful-ai-models-will-destroy-californias-nascent-industry)

**Exclusive: Renowned Experts Pen Support for California's Landmark AI Safety Bill**
Renowned experts Yoshua Bengio, Geoffrey Hinton, Lawrence Lessig, and Stuart Russell have co-authored a letter urging California lawmakers to support the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act. The bill, which requires AI companies to conduct rigorous safety testing and implement comprehensive safety measures, is seen as the 'bare minimum for effective regulation of this technology.' The experts argue that the next generation of AI systems pose 'severe risks' if developed without sufficient care and oversight. They reject the notion that the bill would hamper innovation, stating that it only applies to the largest AI models and that similar regulations in Europe and China are more restrictive. The letter praises the bill for its 'robust whistleblower protections' and notes that it would be a 'historic mistake' to strike out the basic measures of the bill. The experts emphasize the need for regulation, citing risks posed by autonomous AI agents and the potential for technology companies to prioritize profit over safety.
Original language: en
Publish date: August 07, 2024 09:06 PM
Source:[TIME](https://time.com/7008947/california-ai-bill-letter)

**Opinion: California must not fall for tech industry's false choices about AI**
California's proposed legislation, Senate Bill 1047, aims to establish safety guardrails around artificial intelligence. Critics from Silicon Valley argue that regulation will drive innovation out of California, but this claim is misleading and dangerous. The bill only applies to companies spending hundreds of millions on advanced AI models, and most startups and researchers will feel no impact. The bill has been endorsed by scientists who invented the field, including Yoshua Bengio and Geoffrey Hinton. Critics, including 'effective accelerationist' tech zealots, are lobbying against common sense safety requirements, but Californians overwhelmingly support the bill, with 66% of voters not trusting tech companies to prioritize AI safety on their own. The author, a young person, rejects the idea of being anti-technology and supports the bill as a step towards a future where AI's benefits are shared widely and its harms are mitigated.
Original language: en
Publish date: August 06, 2024 12:30 PM
Source:[The Mercury News](https://www.mercurynews.com/2024/08/06/opinion-california-must-not-fall-for-tech-industrys-false-choices-about-ai)

**California must not fall for tech industry's false choices on AI safety legislation**
Sunny Gandhi, vice president of political affairs at Encode Justice, argues that California's proposed legislation, Senate Bill 1047, is not a debate between Big Tech and government regulation, but rather a necessary step to ensure the responsible development of artificial intelligence. Gandhi emphasizes that the bill only applies to companies spending hundreds of millions on advanced AI models, and that most startups and researchers will feel no impact. Critics from Silicon Valley argue that regulation will drive innovation out of California, but Gandhi claims that this is a misleading and dangerous argument. She notes that major tech companies like Google and Meta have already made promises about AI safety, but are now lobbying against common sense safety requirements. Gandhi concludes that Californians overwhelmingly support policies like SB 1047, and that the choice is not between innovation and safety, but between a future where AI's benefits are shared widely and one where its harms fall disproportionately on vulnerable groups.
Original language: en
Publish date: August 05, 2024 12:30 PM
Source:[NewsBreak](https://www.newsbreak.com/news/3550885675935-california-must-not-fall-for-tech-industry-s-false-choices-on-ai-safety-legislation)

**From Sci-Fi To State Law: California's Plan To Prevent AI Catastrophe**
California's 'Safe and Secure Innovation for Frontier Artificial Intelligence Models Act' (SB-1047) aims to prevent AI catastrophe by requiring companies behind large AI models to implement safety measures. Critics argue that the bill's focus on existential threats could limit research and development for non-threatening AI uses. The bill defines 'safety incidents' as harms leading to 'mass casualties or at least $500 million of damage', and requires AI creators to implement shutdown capabilities and policies. Supporters, including AI experts Geoffrey Hinton and Yoshua Bengio, believe the bill is a necessary precaution against potential catastrophic AI risks. Critics, including tech policy expert Nirit Weiss-Blatt and AI community voice Daniel Jeffries, argue that the bill is based on science fiction fears and could harm technological advancement.
Original language: en
Publish date: July 29, 2024 11:00 PM
Source:[Slashdot](https://yro.slashdot.org/story/24/07/29/2237231/from-sci-fi-to-state-law-californias-plan-to-prevent-ai-catastrophe)

**From sci-fi to state law: California's plan to prevent AI catastrophe**
California's 'Safe and Secure Innovation for Frontier Artificial Intelligence Models Act' (SB-1047) aims to prevent AI catastrophe by requiring companies behind large AI models to implement testing procedures and systems to prevent and respond to 'safety incidents'. Critics argue that the bill's focus on existential threats by future AI models could severely limit research and development for more prosaic, non-threatening AI uses today. The bill defines 'safety incidents' as 'critical harms' that could lead to 'mass casualties or at least $500 million of damage', and requires AI model creators to implement measures to prevent and respond to such incidents. Supporters, including AI luminaries Geoffrey Hinton and Yoshua Bengio, argue that the bill is a necessary step to prevent potential catastrophic harm from advanced AI systems, while critics argue that AI policy shouldn't be led by outlandish fears of future systems that resemble science fiction more than current technology.
Original language: en
Publish date: July 29, 2024 07:05 PM
Source:[Ars Technica](https://arstechnica.com/information-technology/2024/07/from-sci-fi-to-state-law-californias-plan-to-prevent-ai-catastrophe)

**Inside the fight over California's new AI bill**
California state Senator Scott Wiener has introduced a bill, SB 1047, requiring companies training 'frontier models' that cost more than $100 million to do safety testing and be able to shut off their models in the event of a safety incident. The bill has sparked fury from the tech industry, with VC heavyweights Andreessen-Horowitz and Y Combinator publicly condemning the bill. Wiener spoke with Kelsey Piper about the challenges to the bill, including concerns about liability, open source developers, and the potential impact on innovation. He emphasized that the bill is a light-touch regulation and that it does not require a license or strict liability. He also addressed concerns about the shutdown provision and fine-tuning, making amendments to address these issues. Wiener believes that the bill will promote responsible deployment and training of AI models, and that it is not intended to eliminate risk, but rather to ensure that risks are understood and mitigated.
Original language: en
Publish date: July 19, 2024 01:00 PM
Source:[Vox](https://www.vox.com/future-perfect/361562/california-ai-bill-scott-wiener-sb-1047)

**New California AI bill threatens to cripple U.S. innovation**
California legislators are close to passing a bill, Senate Bill 1047, which would stifle innovation and competition in artificial intelligence (AI) development. The bill would require permission from the state at every turn, treating new AI models as dangerous until certified otherwise. This would lead to a regulatory regime that forces technology to advance at the pace of bureaucracy, squashing innovation. The bill would also create a new regulatory agency, the Frontier Model Division (FMD), which would have sweeping authority to define what AI models are 'reasonably able to cause or enable a critical harm'. The FMD would also be able to fund itself via fees levied on companies seeking approval, effectively a tax on new AI models. The bill would cripple the development and dissemination of new open-source AI models, and would likely lead to the creation of AI monopolies. The author argues that the bill ignores the revolutionary benefits that AI may provide and that regulating AI applications based on a rational assessment of risk rather than fear of the technology itself is necessary for the United States to realize these benefits and be competitive with the rest of the world.
Original language: en
Publish date: July 14, 2024 12:55 PM
Source:[San Bernardino Sun](https://www.sbsun.com/2024/07/14/new-california-ai-bill-threatens-to-cripple-u-s-innovation)

**Senate Bill 1047 will crush AI innovation in California**
California's Senate Bill 1047, the Safe and Secure Frontier Artificial Intelligence Act, threatens to crush AI innovation in the state. The bill imposes liability on AI developers for what users do with their products, making it difficult for developers to certify their products and potentially chilling major investment in AI technologies. The bill also creates a new regulatory body, the Frontier Model Division, which would be funded by fees and fines, creating an incentive to levy heavy fines and find creative applications of the law. The bill raises constitutional concerns, as AI development is interstate commerce and states do not have the right to regulate it. The author argues that Congress should pass a preemption bill to prevent bad state laws like this from stopping AI innovation.
Original language: en
Publish date: July 10, 2024 03:29 PM
Source:[Long Beach Press-Telegram](https://www.presstelegram.com/2024/07/10/senate-bill-1047-will-crush-ai-innovation-in-california)

**Why California's AI bill could hurt more than it helps**
California's proposed Safe and Secure Innovation for Frontier Artificial Intelligence Models Act aims to improve AI safety by requiring developers to certify their models are not dangerous. However, the law may slow down critical AI advancements in healthcare, education, and other fields by discouraging innovation and reducing competition. The bill requires developers to provide an annual certification, affirming their AI models do not pose a danger, which is difficult to predict at an early stage. This could lead to developers leaving California for friendlier jurisdictions, and small businesses may face devastating financial losses. The bill also introduces criminal liability dangers and unclear definitions, which could impact creativity and slow down advancements.
Original language: en
Publish date: July 03, 2024 02:00 PM
Source:[Los Angeles Daily News](https://www.dailynews.com/2024/07/03/why-californias-ai-bill-could-hurt-more-than-it-helps)

**AI safety bill passes committee vote in Sacramento**
The Safe and Secure Innovation for Frontier Artificial Intelligence Models Act, introduced in February 2024, has passed a committee vote in Sacramento. The bill was previously approved by the California state Senate in May.
Original language: en
Publish date: July 02, 2024 11:52 PM
Source:[World News Network](https://article.wn.com/view/2024/07/02/AI_safety_bill_passes_committee_vote_in_Sacramento)

**California AI safety bill passes committee vote**
The California state Senate has passed the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act, which requires AI companies to test the safety of their programs and create security measures to prevent manipulation or rogue behavior. The bill, introduced by Sen. Scott Wiener, aims to ensure innovation in AI technology while maintaining safety. However, companies like Meta and Google have expressed concerns that the bill will stifle innovation and create regulatory uncertainty. The bill will now go to the Assembly Appropriations Committee and, if passed, to a full floor vote in August.
Original language: en
Publish date: July 02, 2024 09:35 PM
Source:[The Business Journals](https://www.bizjournals.com/losangeles/news/2024/07/02/ai-regulation-sb-1047-committee.html)

**AI safety bill SB 1047 passes committee vote in Sacramento**
The California state Senate passed the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047) in May 2024, requiring AI companies to test the safety of their programs and create security measures to prevent manipulation or rogue behavior. The bill, introduced by Sen. Scott Wiener, aims to ensure AI innovation does not compromise safety. However, companies like Meta and Google have pushed back, arguing the law should target those who exploit AI, not developers. The bill will go to the Assembly Appropriations Committee in August and, if passed, to a full floor vote later that month.
Original language: en
Publish date: July 02, 2024 09:12 PM
Source:[The Business Journals](https://www.bizjournals.com/sanfrancisco/news/2024/07/02/ai-regulation-sb-1047-committee.html)

**SB 1047 up for vote in Sacramento today**
The Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047) is up for a vote in Sacramento today. The bill was first introduced in February 2024 and passed in May by the California State Senate.
Original language: en
Publish date: July 02, 2024 03:45 PM
Source:[World News Network](https://article.wn.com/view/2024/07/02/SB_1047_up_for_vote_in_Sacramento_today)

**Proposed law to control powerful AI models will destroy California's nascent industry**
A proposed bill in the California State Senate, SB 1047, threatens to stifle the state's AI industry with draconian regulations and government overreach. The bill, titled 'Safe and Secure Innovation for Frontier Artificial Intelligence Models Act', would impose strict restrictions and oversight on companies developing cutting-edge AI models, potentially killing innovation, concentrating power in the hands of tech giants, and costing thousands of jobs. The bill's vague language gives too much power to a new government bureaucracy, making it difficult for startups and researchers to innovate, and contains no concrete provisions to protect consumers.
Original language: en
Publish date: June 11, 2024 04:39 PM
Source:[RocketNews](https://www.rocketnews.com/2024/06/proposed-law-to-control-powerful-ai-models-will-destroy-californias-nascent-industry)

**California AI Safety Bill sparks uproar in Silicon Valley**
A bill, the Safe and Secure Innovation for Frontier Artificial Intelligence Systems Act, has been proposed in California to regulate AI development and ensure safety. The bill requires AI companies to establish rigorous safety frameworks, including a 'kill switch' to disable powerful AI models in case of emergencies. Tech companies are opposing the bill, arguing it is overly restrictive and will stifle innovation. However, AI researchers and experts support the bill, citing the need for guardrails on powerful AI. The bill has sparked controversy, with some questioning the involvement of the Center for AI Safety, a non-profit organization co-sponsoring the bill.
Original language: en
Publish date: June 10, 2024 07:26 AM
Source:[Computing](https://www.computing.co.uk/news/4319956/california-ai-safety-sparks-uproar-silicon-valley)


