2024-10-18 12:32:19,320 - INFO - Formatted articles for 2024-08-08T14:30:00Z:
Here are the relevant news articles:

**From Sci-Fi To State Law: California's Plan To Prevent AI Catastrophe**
California's 'Safe and Secure Innovation for Frontier Artificial Intelligence Models Act' (SB-1047) aims to prevent AI catastrophe by requiring companies behind large AI models to implement safety measures. Critics argue that the bill's focus on existential threats could limit research and development for non-threatening AI uses. The bill defines 'safety incidents' as harms leading to 'mass casualties or at least $500 million of damage', and requires AI creators to implement shutdown capabilities and policies. Supporters, including AI experts Geoffrey Hinton and Yoshua Bengio, believe the bill is a necessary precaution against potential catastrophic AI risks. Critics, including tech policy expert Nirit Weiss-Blatt and AI community voice Daniel Jeffries, argue that the bill is based on science fiction fears and could harm technological advancement.
Original language: en
Publish date: July 29, 2024 11:00 PM
Source:[Slashdot](https://yro.slashdot.org/story/24/07/29/2237231/from-sci-fi-to-state-law-californias-plan-to-prevent-ai-catastrophe)

**Senate Bill 1047 will crush AI innovation in California**
California's Senate Bill 1047, the Safe and Secure Frontier Artificial Intelligence Act, threatens to crush AI innovation in the state. The bill imposes liability on AI developers for what users do with their products, making it difficult for developers to certify their products and potentially chilling major investment in AI technologies. The bill also creates a new regulatory body, the Frontier Model Division, which would be funded by fees and fines, creating an incentive to levy heavy fines and find creative applications of the law. The bill raises constitutional concerns, as AI development is interstate commerce and states do not have the right to regulate it. The author argues that Congress should pass a preemption bill to prevent bad state laws like this from stopping AI innovation.
Original language: en
Publish date: July 10, 2024 03:29 PM
Source:[Long Beach Press-Telegram](https://www.presstelegram.com/2024/07/10/senate-bill-1047-will-crush-ai-innovation-in-california)

**AI safety bill SB 1047 passes committee vote in Sacramento**
The California state Senate passed the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047) in May 2024, requiring AI companies to test the safety of their programs and create security measures to prevent manipulation or rogue behavior. The bill, introduced by Sen. Scott Wiener, aims to ensure AI innovation does not compromise safety. However, companies like Meta and Google have pushed back, arguing the law should target those who exploit AI, not developers. The bill will go to the Assembly Appropriations Committee in August and, if passed, to a full floor vote later that month.
Original language: en
Publish date: July 02, 2024 09:12 PM
Source:[The Business Journals](https://www.bizjournals.com/sanfrancisco/news/2024/07/02/ai-regulation-sb-1047-committee.html)

**SB 1047 up for vote in Sacramento today**
The Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047) is up for a vote in Sacramento today. The bill was first introduced in February 2024 and passed in May by the California State Senate.
Original language: en
Publish date: July 02, 2024 03:45 PM
Source:[World News Network](https://article.wn.com/view/2024/07/02/SB_1047_up_for_vote_in_Sacramento_today)

**Proposed law to control powerful AI models will destroy California's nascent industry**
A proposed bill in the California State Senate, SB 1047, threatens to stifle the state's AI industry with draconian regulations and government overreach. The bill, titled 'Safe and Secure Innovation for Frontier Artificial Intelligence Models Act', would impose strict restrictions and oversight on companies developing cutting-edge AI models, potentially killing innovation, concentrating power in the hands of tech giants, and costing thousands of jobs. The bill's vague language gives too much power to a new government bureaucracy, making it difficult for startups and researchers to innovate, and contains no concrete provisions to protect consumers.
Original language: en
Publish date: June 11, 2024 04:39 PM
Source:[RocketNews](https://www.rocketnews.com/2024/06/proposed-law-to-control-powerful-ai-models-will-destroy-californias-nascent-industry)

**Analysis | California is weighing a flurry of sprawling tech bills  --  again**
California lawmakers are considering a flurry of tech bills, including proposals on artificial intelligence, child online safety, and digital advertising. The bills aim to regulate the tech sector, with some experts warning that they could have a significant impact nationwide. One bill, S.B. 1047, would force companies to test their most powerful AI models before rolling them out, while another, A.B. 3172, would expose social media platforms to greater civil penalties if they don't exercise 'ordinary care' toward children on their services. Tech companies have fiercely resisted efforts to expand their liability for harms users' experience on their platforms. California lawmakers are also proposing expanded protections against collecting data from minors and against AI-generated sexually explicit material of minors. Additionally, there are proposals to boost reeling news publishers by redirecting revenue to them from large technology companies. 'California has outsize influence on tech policy.... Whatever bills pass this session in California are going to be very impactful nationwide,' said Center for Democracy and Technology senior policy counsel Matt Scherer. 'One state can be an aberration. Two states is a trend,' he added.
Original language: en
Publish date: August 08, 2024 01:00 PM
Source:[Washington Post](https://www.washingtonpost.com/politics/2024/08/08/california-is-weighing-flurry-sprawling-tech-bills-again/)

**California AI Act: 'Godmother of AI' Fei-Fei Li Warns of Potential Consequences**
Stanford Professor Fei-Fei Li, known as the 'Godmother of AI', is concerned about the California AI Act (SB-1047) and its potential impact on AI development in California and the US. She warns that the law will 'gag' developers and hinder innovation, as AI model providers will be held responsible for misuse. Li argues that it is impossible to exclude all possible scenarios for misuse as a developer. She is also concerned about the requirement to implement a 'kill switch' in models that exceed a certain size, which she believes will make developers more cautious and less willing to contribute to AI development. This, in turn, will affect the Open-Source community and limit the availability of information for scientists. Li notes that the law does not address the potential dangers of AI, such as bias and deepfakes. She offers her expertise to Senator Scott Wiener, who is responsible for the bill. Li is not the only critic of the law, and some have expressed concerns that it will hinder innovation and increase compliance costs.
Original language: de
Publish date: August 08, 2024 10:20 AM
Source:[heise online](https://www.heise.de/news/Godmother-of-AI-sorgt-sich-vor-kalifornischem-KI-Gesetz-9828248.html)

**Will this California bill to regulate AI protect consumers or gut tech?**
California is considering Senate Bill 1047, which aims to regulate artificial intelligence (AI) and prevent serious harm. The bill requires companies producing the largest AI models to test and modify those models to avoid facilitating harm. Simon Last, co-founder of Notion, supports the bill, stating that it strikes a balance between protecting public safety and supporting innovation. He argues that the bill applies to companies building the next generation of AI systems that cost more than $100 million to train, and that it includes whistleblower protections for employees who report safety concerns. In contrast, Paul Lekas, a public policy head at the Software & Information Industry Assn., opposes the bill, arguing that it would prohibit developers from releasing AI models that can be adapted to address needs of California consumers and businesses. He claims that the bill goes too far and would force emerging and established companies to weigh near-impossible standards for compliance against the value of doing business elsewhere.
Original language: en
Publish date: August 08, 2024 10:04 AM
Source:[Los Angeles Times](https://www.latimes.com/opinion/story/2024-08-08/california-artificial-intelligence-regulation-bill-wiener)

**Sacramento's AI fight goes national**
A bill to regulate artificial intelligence (AI) in California, Senate Bill 1047, has sparked a national debate. The bill, proposed by Senator Scott Wiener, requires safety assessments for large-scale AI models. Critics, including Silicon Valley Rep. Zoe Lofgren and venture capital firms a16z and Y Combinator, argue that the bill would undermine AI innovation and harm the state economy. Proponents, including renowned professors Yoshua Bengio and Geoffrey Hinton, argue that the bill is necessary to regulate the technology and prevent unintended consequences. The bill has passed through several committees with wide majorities in support, but its fate is uncertain as it awaits a vote on the Assembly floor and potential approval from Governor Gavin Newsom.
Original language: en
Publish date: August 08, 2024 08:00 AM
Source:[POLITICO](https://www.politico.com/newsletters/california-playbook/2024/08/08/sacramentos-ai-fight-goes-national-00173167)

**Exclusive: Renowned Experts Pen Support for California's Landmark AI Safety Bill**
Renowned experts Yoshua Bengio, Geoffrey Hinton, Lawrence Lessig, and Stuart Russell have co-authored a letter urging California lawmakers to support the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act. The bill, which requires AI companies to conduct rigorous safety testing and implement comprehensive safety measures, is seen as the 'bare minimum for effective regulation of this technology.' The experts argue that the next generation of AI systems pose 'severe risks' if developed without sufficient care and oversight. They reject the notion that the bill would hamper innovation, stating that it only applies to the largest AI models and that similar regulations in Europe and China are more restrictive. The letter praises the bill for its 'robust whistleblower protections' and notes that it would be a 'historic mistake' to strike out the basic measures of the bill. The experts emphasize the need for regulation, citing risks posed by autonomous AI agents and the potential for technology companies to prioritize profit over safety.
Original language: en
Publish date: August 07, 2024 09:06 PM
Source:[TIME](https://time.com/7008947/california-ai-bill-letter)

**'The Godmother of AI' says California's well-intended AI bill will harm the U.S. ecosystem**
The 'Godmother of AI' warns that California's AI bill, SB-1047, will harm the U.S. ecosystem. The bill, aimed at regulating AI models, will unduly punish developers, stifle innovation, and hamstring academic AI research. It will also devastate the open-source community by mandating a 'kill switch' in AI models. The bill fails to address the potential harms of AI advancement, including bias and deepfakes, and will instead restrict innovation across sectors. The author calls for a 'moonshot mentality' to spur AI education, research, and development, and offers collaboration to Senator Scott Wiener to craft AI legislation that will truly build a technology-enabled, human-centered society.
Original language: en
Publish date: August 06, 2024 12:35 PM
Source:[Fortune](https://fortune.com/2024/08/06/godmother-of-ai-says-californias-ai-bill-will-harm-us-ecosystem-tech-politics/)

**Opinion: California must not fall for tech industry's false choices about AI**
California's proposed legislation, Senate Bill 1047, aims to establish safety guardrails around artificial intelligence. Critics from Silicon Valley argue that regulation will drive innovation out of California, but this claim is misleading and dangerous. The bill only applies to companies spending hundreds of millions on advanced AI models, and most startups and researchers will feel no impact. The bill has been endorsed by scientists who invented the field, including Yoshua Bengio and Geoffrey Hinton. Critics, including 'effective accelerationist' tech zealots, are lobbying against common sense safety requirements, but Californians overwhelmingly support the bill, with 66% of voters not trusting tech companies to prioritize AI safety on their own. The author, a young person, rejects the idea of being anti-technology and supports the bill as a step towards a future where AI's benefits are shared widely and its harms are mitigated.
Original language: en
Publish date: August 06, 2024 12:30 PM
Source:[The Mercury News](https://www.mercurynews.com/2024/08/06/opinion-california-must-not-fall-for-tech-industrys-false-choices-about-ai)

**California must not fall for tech industry's false choices on AI safety legislation**
Sunny Gandhi, vice president of political affairs at Encode Justice, argues that California's proposed legislation, Senate Bill 1047, is not a debate between Big Tech and government regulation, but rather a necessary step to ensure the responsible development of artificial intelligence. Gandhi emphasizes that the bill only applies to companies spending hundreds of millions on advanced AI models, and that most startups and researchers will feel no impact. Critics from Silicon Valley argue that regulation will drive innovation out of California, but Gandhi claims that this is a misleading and dangerous argument. She notes that major tech companies like Google and Meta have already made promises about AI safety, but are now lobbying against common sense safety requirements. Gandhi concludes that Californians overwhelmingly support policies like SB 1047, and that the choice is not between innovation and safety, but between a future where AI's benefits are shared widely and one where its harms fall disproportionately on vulnerable groups.
Original language: en
Publish date: August 05, 2024 12:30 PM
Source:[NewsBreak](https://www.newsbreak.com/news/3550885675935-california-must-not-fall-for-tech-industry-s-false-choices-on-ai-safety-legislation)

**California Proposes Law to Regulate Artificial Intelligence**
A draft law has been proposed in California to regulate the development and use of artificial intelligence (AI). The law aims to address the potential risks and consequences of AI, such as the development of autonomous weapons and the manipulation of financial markets. Senator Scott Wiener, a Democrat from San Francisco, said, 'The goal here is to anticipate the risks, not wait for them to happen.' The draft law has been met with opposition from tech companies, including Google, Meta, and Way Combinator, who argue that it will stifle innovation and hinder the development of open-source AI. Critics of the draft law say it will impose 'unreasonable obligations' on developers and 'grossly misinterpret' how advanced AI systems are built. The law would establish a new regulatory agency called the 'Frontier Model Division' and create a public-private computing program called 'Cal Compy' to develop and deploy AI models. The program would focus on promoting 'fair' innovation in AI and providing operational expertise, user support, and innovation incentives.
Original language: ar
Publish date: August 04, 2024 01:18 PM
Source:[Assawsana News](https://www.assawsana.com/article/638171)

**California Draft Law Aims to Regulate Advanced Artificial Intelligence**
A draft law in California aims to regulate the development and deployment of advanced artificial intelligence (AI) models. The law, proposed by Senator Scott Wiener, aims to prevent the misuse of AI and mitigate potential risks. Wiener stated, 'The goal here is to anticipate risks rather than wait for them to happen, which is what we do all the time.' The law would establish a new regulatory agency, 'Frontier Model Division', and create a public-private partnership, 'Cal Compu', to develop and deploy AI models. However, critics argue that the law would stifle innovation and hinder the development of open-source AI. They claim that the law misinterprets how advanced AI systems are built and imposes 'unreasonable' obligations on developers. Meta's Vice President and Chief Privacy Officer, Rob Sherman, wrote to Wiener in June, stating that AI systems 'are built by multiple parties with complex functions', including developers, publishers, and users. Sherman argued that the law fails to consider the ecosystem and assign responsibility accordingly, imposing 'unreasonable' obligations on developers for parts of the system they do not control. Wiener disagrees and has accepted many amendments during the process. He stated, 'Risk assessments are a critical requirement, and these large labs have already committed to implementing them.' Wiener added, 'If there is a significant risk of catastrophic harm, developers should take steps to mitigate that risk, making it less likely to occur.' The law would apply only to developers of large-scale AI models, particularly those with computing power exceeding $100 million to implement safety and security protocols. Additionally, the law may impose penalties on companies that fail to report AI-related safety incidents, including those that exacerbate severe harm, models that engage in prohibited behavior, and failures to prevent the use of powerful AI.
Original language: ar
Publish date: August 04, 2024 05:36 AM
Source:[(وكالة أنباء سرايا (حرية سقفها السماء](https://www.sarayanews.com/article/949200/%D9%85%D8%B3%D9%88%D8%AF%D8%A9-%D9%82%D8%A7%D9%86%D9%88%D9%86-%D9%81%D9%8A-%D9%83%D8%A7%D9%84%D9%8A%D9%81%D9%88%D8%B1%D9%86%D9%8A%D8%A7-%D8%AA%D8%B3%D8%B9%D9%89-%D9%84%D8%AA%D9%88%D9%81%D9%8A%D8%B1-%D8%A7%D9%84%D8%AD%D9%85%D8%A7%D9%8A%D8%A9-%D9%85%D9%86-%D9%83%D9%88%D8%A7%D8%B1%D8%AB-%D8%A7%D9%84%D8%B0%D9%83%D8%A7%D8%A1)

**US Draft Law Aims to Protect Against AI Catastrophes**
A draft law in the United States aims to provide protection from the catastrophic consequences of artificial intelligence. The law, proposed by Senator Scott Wiener, would establish a new regulatory agency called 'Frontier Model Division' to oversee the development and deployment of advanced artificial intelligence models. The agency would also create a public-private partnership called 'Cal Compu' to develop and deploy AI models on a large scale. However, critics argue that the law would stifle innovation and hinder the development of open-source AI. They claim that the law would impose 'unreasonable obligations' on developers and 'grossly misinterpret' how advanced AI systems are built. The law would also impose penalties on companies that fail to report AI-related safety incidents, including those that exacerbate severe harm, models that engage in prohibited behavior, and failures to prevent the use of powerful AI. The law has already passed the Senate and is currently being reviewed by the Appropriations Committee before being sent to the Governor's office.
Original language: ar
Publish date: August 04, 2024 05:03 AM
Source:[برس بي اليمن](https://ar.pressbee.net/show8457614.html)

**California Pushes AI Regulation Bill**
California has introduced a bill to regulate artificial intelligence (AI) and address its potential risks. The legislation, supported by State Senator Scott Wiener, proposes the establishment of the Frontier Model Division to oversee AI development and the Cal Compute group to foster equitable AI innovation. Supporters believe it is necessary to mitigate potential harms, such as autonomous weapons and AI-driven cyberattacks, while critics argue it could stifle innovation and impose unfair burdens on AI developers. The bill has passed the California State Senate and is moving through the legislative process, potentially setting a precedent for AI regulation across the United States.
Original language: en
Publish date: August 03, 2024 07:08 PM
Source:[SeeNews](https://see.news/california-pushes-ai-regulation-bill)

**California Draft Law Aims to Regulate Artificial Intelligence**
A draft law in California aims to provide protection from the risks of artificial intelligence. The law, proposed by Senator Scott Wiener, aims to regulate the development and deployment of advanced AI models through the creation of a new regulatory agency called 'Frontier Model Division'. The agency will oversee the development and deployment of AI models, and ensure that they are safe and secure. The law also proposes the creation of a public-private partnership called 'Cal Compu' to develop and deploy AI models for the public good. However, critics of the law argue that it will stifle innovation and hinder the development of open-source AI. They also argue that the law is overly broad and will impose unreasonable burdens on developers. Rob Sherman, Vice President and Chief Privacy Officer at Meta, has expressed concerns that the law does not take into account the complex ecosystem of AI development and deployment, and will impose unreasonable burdens on developers. Wiener has responded to these concerns, saying that the law is necessary to ensure that AI is developed and deployed safely and securely. He also said that the law will only apply to developers who create and deploy AI models that are widely used, and will not impose unreasonable burdens on small developers. The law has been passed by the Senate and is currently being considered by the Appropriations Committee. It will also be subject to a vote before it reaches the Governor's office.
Original language: ar
Publish date: August 03, 2024 11:47 AM
Source:[Aljazeera](https://www.aljazeera.net/tech/2024/8/3/%d9%85%d8%b3%d9%88%d8%af%d8%a9-%d9%82%d8%a7%d9%86%d9%88%d9%86-%d9%81%d9%8a-%d9%83%d8%a7%d9%84%d9%8a%d9%81%d9%88%d8%b1%d9%86%d9%8a%d8%a7-%d8%aa%d8%b3%d8%b9%d9%89-%d9%84%d8%aa%d9%88%d9%81%d9%8a%d8%b1)

**U.S. Tech Legislative, Regulatory & Litigation Update**
The US has seen significant developments in AI legislation, regulation, and litigation in the second quarter of 2024. Key highlights include: The American Privacy Rights Act of 2024 (APRA) was introduced in the House, but no longer requires algorithm impact assessments. The Generative AI Copyright Disclosure Act of 2024 was introduced to require notice to the Register of Copyrights for copyrighted works used in training datasets. The Senate AI Working Group released an AI Roadmap, emphasizing the need for best practices and human oversight. The Federal Communications Commission (FCC) proposed a rulemaking to require disclosure of AI-generated content in political ads. The Department of Homeland Security (DHS) established an AI Safety and Security Board to advise on safe and secure AI development. The White House announced new principles to protect workers from AI dangers. The President's Council of Advisors on Science and Technology (PCAST) released a report recommending actions to accelerate scientific discovery with AI. State legislatures have enacted laws regulating AI-generated content, including election-related synthetic content, AI-generated CSAM, and intimate imagery. California has passed several bills regulating AI, including frontier models, training data, content labeling, and social media platforms. AI litigation developments include new copyright complaints against OpenAI and Microsoft, and record labels against companies using copyrighted sound recordings to train generative AI models.
Original language: en
Publish date: July 31, 2024 06:19 PM
Source:[Inside Privacy](https://www.insideprivacy.com/technology/u-s-tech-legislative-regulatory-litigation-update-second-quarter-2024)

**OpenAI Supports Senate Bills to Promote AI Safety and Access**
OpenAI has expressed its support for three US Senate bills aimed at promoting AI safety and accessibility. The bills, including the NSF AI Education Act, the CREATE AI Act, and the Future of AI Innovation Act, aim to enhance AI safety and accessibility. OpenAI's Vice President of Global Affairs, Anna Makanju, stated, 'The goal of this legislation is to get congressional support for the US AI Safety Institute, a group dedicated to developing best practices for the secure application of cutting-edge AI systems.' The bills aim to promote the ethical development of AI technologies and ensure their use prioritizes safety and ethical issues. The European Union has also introduced the Artificial Intelligence Act, which will be implemented gradually over several years to give organizations time to adjust and meet the new requirements. The Act will prohibit AI systems that take advantage of personal weaknesses, steal facial photos without authorization, or build databases of recognized faces without permission. The goals of the Act are to protect privacy and prevent the improper use of AI technologies.
Original language: en
Publish date: July 31, 2024 03:30 PM
Source:[Herald Sheets](https://heraldsheets.com/openai-supports-senate-bills-to-promote-ai-safety-and-access)

**OpenAI endorses Senate bills that could shape America's AI policy | TechCrunch**
OpenAI has endorsed three Senate bills that could shape the federal government's stance on artificial intelligence. The bills, including the Future of AI Innovation Act, the NSF AI Education Act, and the CREATE AI Act, aim to establish standards and guidelines for AI models, provide federal scholarships for AI research, and establish AI educational resources. OpenAI's Vice President of Global Affairs, Anna Makanju, said, 'We have consistently supported the mission of the institute, which leads the U.S. government's efforts to ensure that frontier AI systems are developed and deployed safely.' OpenAI's endorsements are seen as a way to build goodwill with federal lawmakers and get a seat at the table on future conversations about AI regulation, as the company is likely to face regulatory scrutiny moving forward.
Original language: en
Publish date: July 31, 2024 03:45 AM
Source:[TechCrunch](https://techcrunch.com/2024/07/30/openai-endorses-senate-bills-that-could-shape-americas-ai-policy/)

**From Sci-Fi To State Law: California's Plan To Prevent AI Catastrophe**
California's 'Safe and Secure Innovation for Frontier Artificial Intelligence Models Act' (SB-1047) aims to prevent AI catastrophe by requiring companies behind large AI models to implement safety measures. Critics argue that the bill's focus on existential threats could limit research and development for non-threatening AI uses. The bill defines 'safety incidents' as harms leading to 'mass casualties or at least $500 million of damage', and requires AI creators to implement shutdown capabilities and policies. Supporters, including AI experts Geoffrey Hinton and Yoshua Bengio, believe the bill is a necessary precaution against potential catastrophic AI risks. Critics, including tech policy expert Nirit Weiss-Blatt and AI community voice Daniel Jeffries, argue that the bill is based on science fiction fears and could harm technological advancement.
Original language: en
Publish date: July 29, 2024 11:00 PM
Source:[Slashdot](https://yro.slashdot.org/story/24/07/29/2237231/from-sci-fi-to-state-law-californias-plan-to-prevent-ai-catastrophe)

**From sci-fi to state law: California's plan to prevent AI catastrophe**
California's 'Safe and Secure Innovation for Frontier Artificial Intelligence Models Act' (SB-1047) aims to prevent AI catastrophe by requiring companies behind large AI models to implement testing procedures and systems to prevent and respond to 'safety incidents'. Critics argue that the bill's focus on existential threats by future AI models could severely limit research and development for more prosaic, non-threatening AI uses today. The bill defines 'safety incidents' as 'critical harms' that could lead to 'mass casualties or at least $500 million of damage', and requires AI model creators to implement measures to prevent and respond to such incidents. Supporters, including AI luminaries Geoffrey Hinton and Yoshua Bengio, argue that the bill is a necessary step to prevent potential catastrophic harm from advanced AI systems, while critics argue that AI policy shouldn't be led by outlandish fears of future systems that resemble science fiction more than current technology.
Original language: en
Publish date: July 29, 2024 07:05 PM
Source:[Ars Technica](https://arstechnica.com/information-technology/2024/07/from-sci-fi-to-state-law-californias-plan-to-prevent-ai-catastrophe)

**California's AI Legislation: A Battleground for Regulation**
California is a battleground for artificial intelligence (AI) legislation, with Republicans committed to reversing federal restrictions on AI, while Democrats in the state legislature are pushing for stricter regulations. A proposed law, written by Senator Scott Wiener, would require large and well-funded companies to test their AI for catastrophic risks before releasing it to the public. The law has sparked opposition from the tech industry, with leaders arguing that it would stifle innovation and create unnecessary bureaucracy. Meanwhile, some experts warn that the risks of AI are being underestimated, and that the technology could be used to cause harm. The debate highlights the challenges of regulating AI, and the need for a balanced approach that balances innovation with safety and security concerns.
Original language: es
Publish date: July 19, 2024 06:56 PM
Source:[Infobae](https://www.infobae.com/wapo/2024/07/19/california-es-un-campo-de-batalla-para-los-proyectos-de-ley-sobre-inteligencia-artificial-mientras-trump-planea-frenar-la-regulacion)

**Inside the fight over California's new AI bill**
California state Senator Scott Wiener has introduced a bill, SB 1047, requiring companies training 'frontier models' that cost more than $100 million to do safety testing and be able to shut off their models in the event of a safety incident. The bill has sparked fury from the tech industry, with VC heavyweights Andreessen-Horowitz and Y Combinator publicly condemning the bill. Wiener spoke with Kelsey Piper about the challenges to the bill, including concerns about liability, open source developers, and the potential impact on innovation. He emphasized that the bill is a light-touch regulation and that it does not require a license or strict liability. He also addressed concerns about the shutdown provision and fine-tuning, making amendments to address these issues. Wiener believes that the bill will promote responsible deployment and training of AI models, and that it is not intended to eliminate risk, but rather to ensure that risks are understood and mitigated.
Original language: en
Publish date: July 19, 2024 01:00 PM
Source:[Vox](https://www.vox.com/future-perfect/361562/california-ai-bill-scott-wiener-sb-1047)

**Senators seek to advance AI capabilities at national labs**
Senators Joe Manchin and Lisa Murkowski introduced the Department of Energy AI Act to expand artificial intelligence capabilities across the 17 national laboratories. The bill aims to deploy frontier AI models to help researchers visualize datasets in multiple scientific domains. The bill authorizes $12 billion in spending over five years to launch the Frontiers in Artificial Intelligence for Science, Security, and Technology program, which will develop AI capabilities, workforce, data, and computing capabilities. The bill also establishes AI risk evaluation and mitigation programs, creates a strategic plan for AI advancement, and authorizes funding for multidisciplinary AI Research and Development Centers.
Original language: en
Publish date: July 17, 2024 08:37 PM
Source:[Defense One](https://www.defenseone.com/technology/2024/07/senators-seek-advance-ai-capabilities-national-labs/398133)

**California Bill Aims to Regulate AI to Ensure Safety**
A controversial bill in California aims to regulate AI to ensure its safety. The bill, SB-1047, has sparked a heated debate between those who believe AI should be regulated to prevent potential risks and those who argue that regulation would stifle innovation. The bill requires companies that spend more than $100 million on AI development to conduct regular security tests and report any incidents. Critics argue that the bill is vague and could lead to over-regulation, while supporters say it is necessary to ensure the responsible development of AI. The bill has been met with opposition from some major tech companies, including a16z and Y Combinator, who argue that it would stifle innovation and give too much power to a few large companies. On the other hand, some AI experts and organizations, such as Encode Justice, support the bill, saying it is necessary to ensure the safety and ethics of AI development. The bill is expected to be voted on in August and has sparked a heated debate in the tech community.
Original language: es
Publish date: July 16, 2024 08:50 PM
Source:[Lado.mx](https://lado.mx/noticia.php?id=16256515)

**New California AI bill threatens to cripple U.S. innovation**
California legislators are close to passing a bill, Senate Bill 1047, which would stifle innovation and competition in artificial intelligence (AI) development. The bill would require permission from the state at every turn, treating new AI models as dangerous until certified otherwise. This would lead to a regulatory regime that forces technology to advance at the pace of bureaucracy, squashing innovation. The bill would also create a new regulatory agency, the Frontier Model Division (FMD), which would have sweeping authority to define what AI models are 'reasonably able to cause or enable a critical harm'. The FMD would also be able to fund itself via fees levied on companies seeking approval, effectively a tax on new AI models. The bill would cripple the development and dissemination of new open-source AI models, and would likely lead to the creation of AI monopolies. The author argues that the bill ignores the revolutionary benefits that AI may provide and that regulating AI applications based on a rational assessment of risk rather than fear of the technology itself is necessary for the United States to realize these benefits and be competitive with the rest of the world.
Original language: en
Publish date: July 14, 2024 12:55 PM
Source:[San Bernardino Sun](https://www.sbsun.com/2024/07/14/new-california-ai-bill-threatens-to-cripple-u-s-innovation)

**Senate Bill 1047 will crush AI innovation in California**
California's Senate Bill 1047, the Safe and Secure Frontier Artificial Intelligence Act, threatens to crush AI innovation in the state. The bill imposes liability on AI developers for what users do with their products, making it difficult for developers to certify their products and potentially chilling major investment in AI technologies. The bill also creates a new regulatory body, the Frontier Model Division, which would be funded by fees and fines, creating an incentive to levy heavy fines and find creative applications of the law. The bill raises constitutional concerns, as AI development is interstate commerce and states do not have the right to regulate it. The author argues that Congress should pass a preemption bill to prevent bad state laws like this from stopping AI innovation.
Original language: en
Publish date: July 10, 2024 03:29 PM
Source:[Long Beach Press-Telegram](https://www.presstelegram.com/2024/07/10/senate-bill-1047-will-crush-ai-innovation-in-california)

**California's Proposed AI Regulation Sparks Debate**
California lawmakers are considering a new law, SB 1047, aimed at controlling powerful AI systems in the state. The law, proposed by Senator Scott Weiner, requires big AI models to have emergency shut-off switches and undergo audits by outside experts to ensure they meet safety standards. Critics worry that the law could slow down innovation by limiting open-source AI projects and putting strict rules on a technology that's still changing fast. However, supporters, including some tech leaders, say the law is necessary to prevent big risks from uncontrolled AI development. A final decision on the law is expected in August 2024, which could make it a landmark in how AI is regulated in California and possibly elsewhere.
Original language: en
Publish date: July 06, 2024 02:50 PM
Source:[The News Chronicle](https://thenews-chronicle.com/californias-proposed-ai-regulation-sparks-debate)

**California advances unique safety regulations for AI companies despite tech firm opposition**
California lawmakers have advanced a unique bill that requires artificial intelligence companies to test their systems and add safety measures to prevent potential harm, such as wiping out the state's electric grid or helping build chemical weapons. The bill is opposed by tech companies, including Meta and Google, who argue it targets developers and should focus on those who use AI for harm. Democratic state Sen. Scott Wiener, the bill's author, says it provides reasonable safety standards and prevents 'catastrophic harms' from powerful AI models. The bill would only apply to systems that cost more than $100 million in computing power to train, and would create a new state agency to oversee developers and provide best practices.
Original language: en
Publish date: July 05, 2024 10:48 PM
Source:[ABC15 Arizona](https://www.abc15.com/science-and-tech/artificial-intelligence/california-advances-unique-safety-regulations-for-ai-companies-despite-tech-firm-opposition)

**The Authoritarian Side of Effective Altruism Comes for AI**
The effective altruism (E.A.) movement, which prioritizes doing the most good per dollar spent, has a dark side: a faction of doomsayers who believe artificial intelligence (AI) poses an existential risk. This faction, backed by hundreds of millions of dollars, is pushing for authoritarian legislation to regulate AI development. The Responsible Advanced Artificial Intelligence Act (RAAIA) and California's Senate Bill 1047 would create agencies with dictatorial powers to govern AI systems, impose arbitrary conditions on research, and punish developers for perceived wrongdoing. These bills are a threat to democratic checks and balances and would stifle innovation.
Original language: en
Publish date: July 05, 2024 12:30 PM
Source:[Yahoo](https://www.yahoo.com/news/authoritarian-side-effective-altruism-comes-123022241.html)

**California Advances Unique Safety Regulations for AI Companies Despite Tech Firm opposition**
California lawmakers have advanced a bill that requires artificial intelligence companies to test their systems and add safety measures to prevent potential harm, such as wiping out the state's electric grid or helping build chemical weapons. The bill is opposed by tech companies, including Meta and Google, who argue it targets developers and not those who use AI for harm. Democratic state Sen. Scott Wiener, the author of the bill, says it provides reasonable safety standards to prevent 'catastrophic harms' from powerful AI models. The bill would only apply to systems that cost more than $100 million in computing power to train, and would not create new criminal charges for AI developers whose models were exploited for harm. Democratic Gov. Gavin Newsom has expressed support for the bill, but has also warned against overregulation. A growing coalition of tech companies argue the requirements would discourage companies from developing large AI systems or keeping their technology open-source.
Original language: en
Publish date: July 04, 2024 03:11 PM
Source:[SecurityWeek](https://www.securityweek.com/california-advances-unique-safety-regulations-for-ai-companies-despite-tech-firm-opposition)

**California's controversial AI safety bill worries about nuclear war, catastrophic harm**
California's proposed AI safety bill, SB 1047, has sparked controversy in the tech industry. The bill aims to regulate large frontier AI models and hold developers responsible for potential catastrophic dangers. Opponents argue that it would kill innovation and doom the AI industry, while supporters believe it's necessary to prevent AI from being used to create weapons of mass destruction. The bill requires developers to comply with safety standards, undergo independent audits, and have an inbuilt kill switch for emergencies. Critics argue that it would eliminate open source AI models and place an unfair regulatory burden on companies.
Original language: en
Publish date: July 04, 2024 12:46 PM
Source:[The Indian Express](https://indianexpress.com/article/technology/tech-news-technology/californias-controversial-ai-bill-all-you-need-to-know-9432922)

**California Senator Responds To AI Safety Bill Critics**
California Senator Scott Weiner has written a letter responding to criticism from venture capitalists Y Combinator (YC) and Andreessen Horowitz (a16z) of the recently passed AI Safety Bill. The bill prohibits large-scale and powerful AI systems from aiding in the development of certain weapons and requires developers to implement safety precautions. Weiner addresses several points raised by YC, including claims that the bill would harm the state's tech industry, create new liability risks, and discourage innovation. He argues that the bill is a 'light touch approach' to AI safety and does not ban any models or require state licensure. Weiner also clarifies several alleged inaccuracies in YC's letter, including the bill's application to startups, liability provisions, and definition of 'frontier model'.
Original language: en
Publish date: July 04, 2024 10:20 AM
Source:[MediaNama](https://www.medianama.com/2024/07/223-california-senator-responds-ai-safety-bill-critics)

**California advances unique safety regulations for AI companies**
California lawmakers have advanced a bill that requires artificial intelligence companies to test their systems and add safety measures to prevent potential harm. The bill, which is the first of its kind, aims to reduce risks created by AI and is opposed by venture capital firms and tech companies, including Meta and Google. The bill's author, Democratic state Sen. Scott Wiener, said the proposal would provide reasonable safety standards by preventing 'catastrophic harms' from extremely powerful AI models. The requirements would only apply to systems that cost more than $100 million in computing power to train. The bill also creates a new state agency to oversee developers and provide best practices.
Original language: en
Publish date: July 03, 2024 10:20 PM
Source:[Marin Independent Journal](https://www.marinij.com/2024/07/03/california-advances-unique-safety-regulations-for-ai-companies-despite-tech-firm-opposition)

**Why California's AI bill could hurt more than it helps**
California's proposed Safe and Secure Innovation for Frontier Artificial Intelligence Models Act aims to improve AI safety by requiring developers to certify their models are not dangerous. However, the law may slow down critical AI advancements in healthcare, education, and other fields by discouraging innovation and reducing competition. The bill requires developers to provide an annual certification, affirming their AI models do not pose a danger, which is difficult to predict at an early stage. This could lead to developers leaving California for friendlier jurisdictions, and small businesses may face devastating financial losses. The bill also introduces criminal liability dangers and unclear definitions, which could impact creativity and slow down advancements.
Original language: en
Publish date: July 03, 2024 02:00 PM
Source:[Los Angeles Daily News](https://www.dailynews.com/2024/07/03/why-californias-ai-bill-could-hurt-more-than-it-helps)

**AI safety bill passes committee vote in Sacramento**
The Safe and Secure Innovation for Frontier Artificial Intelligence Models Act, introduced in February 2024, has passed a committee vote in Sacramento. The bill was previously approved by the California state Senate in May.
Original language: en
Publish date: July 02, 2024 11:52 PM
Source:[World News Network](https://article.wn.com/view/2024/07/02/AI_safety_bill_passes_committee_vote_in_Sacramento)

**California AI safety bill passes committee vote**
The California state Senate has passed the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act, which requires AI companies to test the safety of their programs and create security measures to prevent manipulation or rogue behavior. The bill, introduced by Sen. Scott Wiener, aims to ensure innovation in AI technology while maintaining safety. However, companies like Meta and Google have expressed concerns that the bill will stifle innovation and create regulatory uncertainty. The bill will now go to the Assembly Appropriations Committee and, if passed, to a full floor vote in August.
Original language: en
Publish date: July 02, 2024 09:35 PM
Source:[The Business Journals](https://www.bizjournals.com/losangeles/news/2024/07/02/ai-regulation-sb-1047-committee.html)

**AI safety bill SB 1047 passes committee vote in Sacramento**
The California state Senate passed the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047) in May 2024, requiring AI companies to test the safety of their programs and create security measures to prevent manipulation or rogue behavior. The bill, introduced by Sen. Scott Wiener, aims to ensure AI innovation does not compromise safety. However, companies like Meta and Google have pushed back, arguing the law should target those who exploit AI, not developers. The bill will go to the Assembly Appropriations Committee in August and, if passed, to a full floor vote later that month.
Original language: en
Publish date: July 02, 2024 09:12 PM
Source:[The Business Journals](https://www.bizjournals.com/sanfrancisco/news/2024/07/02/ai-regulation-sb-1047-committee.html)

**SB 1047 up for vote in Sacramento today**
The Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047) is up for a vote in Sacramento today. The bill was first introduced in February 2024 and passed in May by the California State Senate.
Original language: en
Publish date: July 02, 2024 03:45 PM
Source:[World News Network](https://article.wn.com/view/2024/07/02/SB_1047_up_for_vote_in_Sacramento_today)

**A misguided California bill would make cutting-edge AI work effectively illegal**
California's Senate Bill 1047, authored by Scott Wiener, aims to regulate artificial intelligence (AI) by requiring developers to swear that their products cannot be used or modified to cause widespread harm. However, this provision could stifle innovation and make it difficult to deploy open-source AI code. Instead, the author suggests that the state focus on addressing the misuse of AI, such as creating severe penalties for those who create virtual child abuse material or deep-faked pornography, and establishing a state-level law enforcement agency to investigate and prosecute cybercrime. The author, Alex Stamos, argues that this approach would be more effective in addressing the real-world problems caused by AI misuse.
Original language: en
Publish date: July 01, 2024 06:53 PM
Source:[Yahoo](https://www.yahoo.com/news/misguided-california-bill-cutting-edge-185302379.html)

**AI companies asked for regulation. Now that it's coming, some are furious**
Tech companies, including Meta and Andreesen Horowitz, are opposing a proposed California bill that would hold them liable for the downstream uses of their artificial intelligence (AI) technology. The bill, SB 1047, aims to regulate AI decision-making programs and prevent catastrophic effects, but companies argue it would stifle innovation and force them to leave California. Proponents of the bill, including the Center for AI Safety, argue that companies should be held responsible for the consequences of their technology. The debate echoes the discussion around social media companies' liability for illegal activities on their platforms.
Original language: en
Publish date: June 28, 2024 07:30 PM
Source:[San Francisco Chronicle](http://www.sfchronicle.com/tech/article/ai-startups-asked-regulation-dislike-bills-19541615.php)

**Big Tech and the little guy**
The article discusses the debate over the regulation of artificial intelligence (AI) in California. Meta, a major tech company, has spoken out against a proposed bill, Senate Bill 1047, which would require large AI models to undergo safety tests. Meta argues that the bill would discourage companies from keeping their technology open-sourced and could narrow the market to a handful of models, making it difficult for startups and small businesses to compete. The article also mentions that the tech industry is applying pressure on Sacramento to slow down the bill's progress. On the other hand, the bill's author, Senator Scott Wiener, argues that the bill is necessary to prevent scenarios like nuclear or biological weapons attacks and that it does not cover startups. The article also mentions that advocates for therapeutic magic mushrooms are giving up on the California Legislature and will instead explore a ballot initiative to legalize psychedelics. Additionally, it reports on an Assemblymember's personal story of being sexually abused as a child and her response to being accused of siding with pedophiles.
Original language: en
Publish date: June 26, 2024 08:00 AM
Source:[POLITICO](https://www.politico.com/newsletters/california-playbook/2024/06/26/big-tech-and-the-little-guy-00165016)

**How a California Bill Could Reshape AI Globally**
A California bill, SB 1047, aims to regulate large AI models by making their providers liable for 'critical harms' and creating a 'shutdown' provision for emergency situations. The bill has sparked a debate between 'accels' and 'decels', with the latter advocating for stricter regulation to prevent AI from causing harm to humanity. The bill has been criticized by many in Silicon Valley, who fear it will stifle innovation and open-source AI development. The bill's supporters, including AI researchers and safety advocates, argue that it is necessary to ensure the responsible development of AI.
Original language: en
Publish date: June 26, 2024 01:00 AM
Source:[Gizmodo India](https://gizmodo.com.au/2024/06/how-a-california-bill-could-reshape-ai-globally)

**AI regulation: While Congress fiddles, California gets it done**
California is taking the lead in AI regulation, passing laws on consumer privacy, bias prevention, and deepfakes, while the federal government has been slow to act. The state's SB-1047 bill aims to regulate large AI models and establish a new agency to verify compliance. The EU has adopted the AI Act, which will be rolled out in stages starting in 2025. The US should follow the EU's lead and craft a unified set of AI regulations to ensure public safety and prevent destructive uses of AI.
Original language: en
Publish date: June 25, 2024 07:22 PM
Source:[Computerworld](https://www.computerworld.com/article/2503219/ai-regulation-while-congress-fiddles-california-gets-it-done.html)

**Doom vs Boom: The Battle to Enshrine AI's Future Into California Law**
A California bill, SB 1047, aims to regulate large AI model providers, making them liable for the potential catastrophic dangers of their AI systems. The bill has sparked a debate between those who want to slow down AI development for safety reasons and those who believe it will stifle innovation. The bill has been criticized by many in Silicon Valley, who argue it will kill the open-source startup ecosystem and benefit big tech companies instead. The bill's supporters, including AI researchers and the Center for AI Safety, believe it is necessary to regulate AI to prevent catastrophic harm. The bill's fate is uncertain, with a vote approaching and Governor Gavin Newsom's signature needed for it to become law.
Original language: en
Publish date: June 24, 2024 11:30 AM
Source:[Gizmodo](https://gizmodo.com/ai-doom-boom-california-law-sb-1047-openai-sam-altman-1851548939)

**Doom vs Boom: The Battle to Regulate AI in California**
A California bill aims to regulate AI models by making their developers responsible for the potential catastrophic risks of their systems. The bill, SB 1047, has sparked a heated debate between those who see it as a necessary step to ensure AI safety and those who believe it will stifle innovation and creativity. The bill requires AI developers to create a 'kill switch' for their models in case of an emergency and establishes a 'Border Models Division' within the California Department of Technology to regulate these models. The bill has been supported by some prominent AI researchers and experts, but opposed by many in the tech industry, including investors, startup founders, and open-source AI enthusiasts. The debate highlights the challenges of regulating AI, including the difficulty of defining what constitutes a 'large' AI model and the potential for AI systems to be used for malicious purposes.
Original language: es
Publish date: June 24, 2024 11:30 AM
Source:[Gizmodo](https://es.gizmodo.com/ai-doom-boom-ley-de-california-sb-1047-openai-sam-altma-1851556318)

**Y Combinator rallies start-ups against California's AI safety bill**
Y Combinator, a Silicon Valley-based accelerator, and a group of AI start-ups have signed an open letter opposing California's Senate Bill 1047, which aims to regulate the development of AI systems. The bill would require developers of large AI models to take precautions to prevent misuse and ensure safety. Y Combinator argues that the responsibility for misuse should rest with those who abuse the tools, not the developers, and that the proposed regulation could stifle innovation and discourage investment in AI research. The letter also criticizes the proposed requirement for a 'kill switch' to quickly deactivate AI models, which Y Combinator claims would impact the development of open-source AI.
Original language: en
Publish date: June 24, 2024 10:05 AM
Source:[Silicon Republic](https://www.siliconrepublic.com/machines/y-combinator-california-ai-safety-bill)

**California AI Public Safety Bill Revised Under Panel Approval**
The California Assembly Privacy and Consumer Protection Committee revised and approved a bill (SB 1047) that aims to place public safety guardrails around developing artificial intelligence models. The bill aims to prevent catastrophic risks such as weapons development and damage to critical infrastructure. Tech companies like Google and Meta Platforms Inc. have lobbied against the bill, but Assemblymembers defend the legislation as 'not onerous'. The bill now heads to the governor for approval.
Original language: en
Publish date: June 19, 2024 12:39 AM
Source:[Bloomberg Law](https://news.bloomberglaw.com/ip-law/california-ai-public-safety-bill-revised-under-panel-approval)

**California's AI Regulation: A Blow to Open-Source Developers**
The California government is planning new regulations for artificial intelligence. The bill has been passed by the Senate and will be put to a vote in August. The bill requires companies based in California to guarantee that they do not develop models with 'dangerous abilities'. Additionally, there will be monthly reports on security tests and the introduction of 'kill and switch', which allows models to be shut down immediately. The bill is a blow to open-source AI model developers, who will be held liable if malicious actors manipulate the freely available source code to cause harm. The harsh criticism from the technology industry has led to a compromise, where open-source developers will not be held liable for modified models. Furthermore, the 'kill and switch' will not apply to open-source models. Another compromise is that the bill will only apply to models with training costs of over $100 million. AI models need regulation, especially when there is the possibility of manipulation. The success of AI will not change; the technology will provide significant added value in areas such as healthcare, IT security, autonomous driving, and administration. The prognosis is confirmed - the rise of AI is far from over. With the DER AKTIONÄR Künstliche Intelligenz index, investors can participate in the development of 13 AI providers, including chip giant Nvidia and tech giants Alphabet and Microsoft.
Original language: de
Publish date: June 17, 2024 04:35 PM
Source:[DER AKTIONÄR](https://www.deraktionaer.de/artikel/indizes/ki-gesetz-verbreitet-angst-und-schrecken-bei-meta-und-co-20359712.html)

**The AI bill that has Big Tech panicked**
California's SB 1047 bill proposes to hold AI developers liable for the harm caused by their technology, similar to how car manufacturers are held liable for car safety. The bill requires companies that spend over $100 million on training AI models to conduct safety testing. Critics argue that this will stifle innovation, but the author of the article believes that the bill is a necessary step to ensure the safety of AI technology. The article discusses the controversy surrounding the bill and the differing opinions among AI researchers on the potential dangers of AI.
Original language: en
Publish date: June 14, 2024 01:00 PM
Source:[Vox](https://www.vox.com/future-perfect/355212/ai-artificial-intelligence-1047-bill-safety-liability)

**Proposed law to control powerful AI models will destroy California's nascent industry**
A proposed bill in the California State Senate, SB 1047, threatens to stifle the state's AI industry with draconian regulations and government overreach. The bill, titled 'Safe and Secure Innovation for Frontier Artificial Intelligence Models Act', would impose strict restrictions and oversight on companies developing cutting-edge AI models, potentially killing innovation, concentrating power in the hands of tech giants, and costing thousands of jobs. The bill's vague language gives too much power to a new government bureaucracy, making it difficult for startups and researchers to innovate, and contains no concrete provisions to protect consumers.
Original language: en
Publish date: June 11, 2024 04:39 PM
Source:[RocketNews](https://www.rocketnews.com/2024/06/proposed-law-to-control-powerful-ai-models-will-destroy-californias-nascent-industry)

**California AI Safety Bill sparks uproar in Silicon Valley**
A bill, the Safe and Secure Innovation for Frontier Artificial Intelligence Systems Act, has been proposed in California to regulate AI development and ensure safety. The bill requires AI companies to establish rigorous safety frameworks, including a 'kill switch' to disable powerful AI models in case of emergencies. Tech companies are opposing the bill, arguing it is overly restrictive and will stifle innovation. However, AI researchers and experts support the bill, citing the need for guardrails on powerful AI. The bill has sparked controversy, with some questioning the involvement of the Center for AI Safety, a non-profit organization co-sponsoring the bill.
Original language: en
Publish date: June 10, 2024 07:26 AM
Source:[Computing](https://www.computing.co.uk/news/4319956/california-ai-safety-sparks-uproar-silicon-valley)

**AI Startups Push to Limit or Kill California Public Safety Bill**
A California bill (SB 1047) aims to establish public safety guardrails around advanced artificial intelligence, but San Francisco startups are pushing back, claiming it could stifle innovation. The bill's author promises changes to protect open-source AI, but the bill awaits action from the Assembly, which has until August 31 to pass it.
Original language: en
Publish date: June 07, 2024 09:00 AM
Source:[Bloomberg Law](https://news.bloomberglaw.com/artificial-intelligence/ai-startups-push-to-limit-or-kill-california-public-safety-bill)


