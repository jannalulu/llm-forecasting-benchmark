2024-10-18 12:31:04,442 - INFO - Formatted articles for 2024-09-02T14:30:00Z:
Here are the relevant news articles:

**Is open source AI possible, let alone the future? Find out at TechCrunch Disrupt 2024**
At TechCrunch Disrupt 2024, Hugging Face's Irene Solaiman and AI2's Ali Farhadi will discuss the possibility of open source AI, a concept that some believe can break the proprietary software cycle that AI has fallen into. Solaiman, Hugging Face's head of global policy, and Farhadi, a leader at AI2, are proponents of openness and transparency in AI, but acknowledge the challenges of making open source AI a reality due to the resource requirements of AI models. The panel discussion will take place at Disrupt 2024 in San Francisco from October 28-30. 'It's certain to be an extremely interesting conversation,' said the moderator. 'What will it take to change the status quo and make open source AI a reality?' 
Original language: en
Publish date: August 27, 2024 03:30 PM
Source:[Yahoo](https://finance.yahoo.com/news/open-source-ai-possible-let-153000459.html)

**Meta Just Launched The Largest 'Open' AI Model In History. Heres Why It Matters**
Meta, the parent company of Facebook, has released the largest 'open' AI model in history, Llama 3.1 405B. This model is considered a 'frontier-level open-source AI model' by Meta's founder and CEO, Mark Zuckerberg. The release of this model is seen as a step towards making AI technology more accessible and transparent. However, some concerns remain about the potential risks and ethical implications of open-source AI, including the lack of quality control and the potential for misuse. Despite these concerns, Meta's move is seen as a positive step towards democratizing AI and ensuring that it serves the greater good.
Original language: en
Publish date: August 02, 2024 08:00 AM
Source:[NDTV](https://www.ndtv.com/india-ai/meta-just-launched-the-largest-open-ai-model-in-history-heres-why-it-matters-6246346)

**Meta Platforms Just Released an Artificial Intelligence (AI) Game-Changer -- And It Could Be Dangerous | The Motley Fool**
Meta has released its Llama 3.1 model, a frontier AI model with 405 billion parameters, which outperforms other models on many parameters. The model is open-source, allowing developers to modify and improve it. Mark Zuckerberg believes this will make Meta the world's most-used AI assistant by the end of the year, surpassing OpenAI. However, there are risks to open-source AI, including privacy and security concerns, which may lead to government scrutiny and regulation. Zuckerberg argues that these risks are outweighed by the benefits of open innovation, but the approach may still face challenges.
Original language: en
Publish date: July 28, 2024 02:40 PM
Source:[The Motley Fool](https://www.fool.com/investing/2024/07/28/meta-platforms-ai-llama-3-point-1-game-changer/)

**AI is approaching an open-source inflection point**
Meta's open-source Llama models have reached an important threshold, with the latest model achieving 'frontier-level' status, comparable to the most powerful AI from companies like OpenAI, Google, and Anthropic. According to Mark Zuckerberg, future Llama models will surpass others to become the world's most advanced from 2025.
Original language: en
Publish date: July 27, 2024 09:21 AM
Source:[The Straits Times](https://www.straitstimes.com/opinion/ai-is-approaching-an-open-source-inflection-point)

**Meta unveils latest artificial intelligence models as it plans open source future**
Meta has unveiled the latest version of its artificial intelligence models, including Llama 3.1 405B, which will be the first 'frontier-level' open source AI model. The company will also release upgraded Llama 3.1 70B and 8B models. According to Meta's CEO Mark Zuckerberg, this move marks a significant step forward in the development of AI technology.
Original language: en
Publish date: July 23, 2024 06:14 PM
Source:[World News Network](https://article.wn.com/view/2024/07/23/Meta_unveils_latest_artificial_intelligence_models_as_it_pla)

**OpenAI's Secret Project 'Strawberry' to Revolutionize ChatGPT**
OpenAI is expected to launch the fifth generation of ChatGPT, codenamed 'Strawberry', which will have improved capabilities, especially in mathematics and programming. According to sources, the new model will be able to solve mathematical problems better than previous AI models. ChatGPT has faced criticism for its performance in mathematics, with many users reporting errors in solving simple problems. Experts attribute these errors to the lack of mathematical information in the data used to train the model. The new model is also expected to have a wider range of advanced cognitive abilities, including solving complex puzzles like the 'Connections' game published by The New York Times. The project has been shrouded in secrecy, but it is believed to have been presented to US national security officials, which is consistent with OpenAI's statement that it will inform the US government about its upcoming AI models before their release. The project is expected to be revealed by September or October, and it may be integrated into the fifth version of ChatGPT or used to improve the quality of the training data for the next AI model, aiming to reduce the 'hallucinations' or errors that are often reported. As reported by 'theinformation', a source close to the project said, 'It will be a major upgrade, and it will be able to solve math problems better than any previous model.' 
Original language: ar
Publish date: September 01, 2024 08:30 AM
Source:[تليكسبريس](https://telexpresse.com/337045.html)

**Meta leads open-source AI boom, Llama downloads surge 10x year-over-year**
Meta has reported a significant surge in the adoption of its open-source Llama models, with downloads approaching 350 million on Hugging Face, a ten-fold increase from last year. The company claims that large enterprises such as Zoom, Spotify, and Goldman Sachs are using the models for various internal and external use cases. This marks a major milestone for open-source AI, which is now rivaling closed-source models in terms of performance and adoption. As Yann LeCun noted, 'Universities, researchers, and engineers are improving Llama and building new products and services.' This success has raised questions about OpenAI's lead in the generative AI space, which has been criticized for failing to deliver frontier AI products beyond announcements. Meta's open-source play appears to be paying off, with Llama becoming the dominant platform in the AI ecosystem.
Original language: en
Publish date: August 31, 2024 04:11 PM
Source:[Knowledia](https://news.knowledia.com/all/all/articles/meta-leads-open-source-ai-boom-llama-downloads-surge-10x-year-over-year-aec17113938d8d0096d5669d0f71e15bc732d322)

**Big Tech Is Very Afraid of a Very Modest AI Safety Bill**
The Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB1047) aims to regulate the development of advanced AI models by requiring safety protocols, including shut-down protocols, to prevent 'critical harm'. Despite recognition among AI executives of the risks their work poses, the bill has become the target of an extraordinary lobbying effort. The bill's opponents claim it will stifle innovation and end 'open source' AI development, but proponents argue it's a necessary step to ensure AI safety. If the bill fails, it will signal a loss of America's capacity to address significant threats. As one author notes, 'Malarkey', the fight is really about the power of money in American politics. The bill requires developers of AI models costing $100,000,000 or more to train or fine-tuned at a cost of $10,000,000 or more to adopt safety protocols to reduce the risk of 'critical harm'.
Original language: en
Publish date: August 30, 2024 05:00 PM
Source:[Knowledia](https://news.knowledia.com/all/all/articles/big-tech-is-very-afraid-of-a-very-modest-ai-safety-bill-dbf5969529fe09911197e4d769f2d70d80576ea5)

**California lawmakers pass extensive AI safety legislation**
The California State Assembly and Senate have passed the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047), a significant regulatory effort for AI in the US. The bill requires AI companies to ensure their systems can be quickly shut down, protect models from unsafe changes, and closely monitor testing for potential risks. Critics, including OpenAI, have raised concerns that the law may unintentionally harm small AI developers, but the bill was revised to address these concerns. Governor Gavin Newsom has until the end of September to approve or veto the bill. Meanwhile, big tech companies have adopted AI safety guidelines, and the European Union is working on clearer rules to protect user data and regulate AI use.
Original language: en
Publish date: August 30, 2024 09:16 AM
Source:[PhoneArena](https://www.phonearena.com/news/california-lawmakers-pass-extensive-ai-safety-legislation_id162041)

**Controversial AI Bill Passes Legislative Vote**
The California legislature has passed the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act, also known as the 'Doomer bill', with a 41-9 vote. The bill, which aims to regulate generative AI, will now go to Gov. Gavin Newsom's desk for either approval or veto by the end of September. The bill requires safety testing of AI models costing over $100 million, a kill switch, third-party auditors, and protections for whistleblowers. However, tech firms, venture capitalists, and politicians like Nancy Pelosi oppose the bill, saying it will stifle innovation and hurt business growth. A Meta spokesperson stated, 'SB-1047 would stifle AI development in California, hurt business growth and job creation, and break from the state's long tradition of fostering open-source innovation.' 
Original language: en
Publish date: August 30, 2024 01:52 AM
Source:[CNET](https://www.cnet.com/tech/services-and-software/controversial-ai-bill-passes-legislative-vote)

**OSI Works to Define 'IA Open Source' and Promote Transparency in AI Development**
The Open Source Initiative (OSI) is working to define what it means for an artificial intelligence (AI) model to be 'Open Source'. The current definition is unclear, and companies like Meta and OpenAI have been criticized for using the term without adhering to traditional Open Source principles. The OSI has assembled a team of 70 experts to create a definition, which includes four fundamental freedoms: the ability to use the model for any purpose without permission, study its functionality, modify it for any purpose, and share it with or without modifications. The definition also emphasizes the need for transparency, including the publication of the model's code, weights, and parameters, as well as metadata about the training data. The OSI is seeking feedback and expects to finalize the definition in October at the All Things Open 2024 conference. A clear definition of 'IA Open Source' could have a significant impact on the development of future AI models, making it easier for companies and individuals to create and share Open Source models.
Original language: es
Publish date: August 29, 2024 08:01 PM
Source:[Xataka](https://www.xataka.com/robotica-e-ia/no-esta-nada-claro-que-ia-open-source-eso-esta-a-punto-cambiar)

**US Government Takes Proactive Approach to Regulating AI**
The US Government has taken a proactive approach to regulating AI by requiring OpenAI and Anthropic to share their AI models with them before launch. According to an official statement published on the NIST website, the two companies have signed a memorandum of understanding with the US AI Safety Institute, allowing the Government to evaluate the safety risks of their models and provide feedback. This move comes at a time when AI legislation is a hot topic, with California recently passing the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047), which requires AI companies operating in the state to implement additional safety measures before training advanced foundation models. Google has also implemented additional safety filters on Gemini. As Elon Musk releases an uncensored AI, the US Government is taking steps to ensure the safety of AI models, with OpenAI's CEO reportedly saying, 'We are committed to working with the US Government to ensure the safe development and deployment of AI.'
Original language: it
Publish date: August 29, 2024 04:41 PM
Source:[Everyeye.it](https://tech.everyeye.it/notizie/usa-mette-maniia-ricevera-modelli-openai-anthropic-anticipo-738806.html)

**California moves a step close to AI regulation**
The California State Assembly has approved the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047), a significant step toward AI regulation in the United States. The bill requires AI companies to implement safety measures, including the ability to quickly shut down models and protect against harmful modifications. Senator Scott Wiener emphasized that the bill is designed to ensure AI labs conduct necessary safety checks. Despite criticism from OpenAI and others, the bill was amended to replace criminal penalties with civil ones and to refine enforcement provisions. Elon Musk, a co-founder of OpenAI, has endorsed the bill, stating, 'This is a tough call and will make some people upset, but, all things considered, I think California should probably pass the SB 1047 AI safety bill.' 
Original language: en
Publish date: August 29, 2024 07:20 AM
Source:[Proactive](https://www.proactiveinvestors.com/companies/news/1055050/california-moves-a-step-close-to-ai-regulation-1055050.html)

**California State Assembly passes sweeping AI safety bill**
The California State Assembly has passed the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act (SB 1047), a significant regulation of artificial intelligence in the US. The bill requires AI companies operating in California to implement precautions before training sophisticated foundation models, including the ability to quickly shut down the model, protect against 'unsafe post-training modifications,' and maintain a testing procedure to evaluate potential risks. Senator Scott Wiener, the bill's author, said SB 1047 is a 'highly reasonable bill' that asks large AI labs to test their models for catastrophic safety risks. Critics, including OpenAI and Anthropic, have argued that the bill is overly focused on catastrophic harms and could harm small, open-source AI developers. The bill was amended to replace potential criminal penalties with civil ones and narrow enforcement powers. The amended bill will now go to the State Senate for a vote, and if passed, will head to Governor Gavin Newsom for approval by the end of September.
Original language: en
Publish date: August 29, 2024 12:09 AM
Source:[The Verge](https://www.theverge.com/2024/8/28/24229068/california-sb-1047-ai-safety-bill-passed-state-assembly-governor-newsom-signature)

**Is open source AI possible, let alone the future? Find out at TechCrunch Disrupt 2024**
At TechCrunch Disrupt 2024, Hugging Face's Irene Solaiman and AI2's Ali Farhadi will discuss the possibility of open source AI, a concept that some believe can break the proprietary software cycle that AI has fallen into. Solaiman, Hugging Face's head of global policy, and Farhadi, a leader at AI2, are proponents of openness and transparency in AI, but acknowledge the challenges of making open source AI a reality due to the resource requirements of AI models. The panel discussion will take place at Disrupt 2024 in San Francisco from October 28-30. 'It's certain to be an extremely interesting conversation,' said the moderator. 'What will it take to change the status quo and make open source AI a reality?' 
Original language: en
Publish date: August 27, 2024 03:30 PM
Source:[Yahoo](https://finance.yahoo.com/news/open-source-ai-possible-let-153000459.html)

**Hugging Face and AI2 to join the AI Stage at Disrupt 2024**
Hugging Face's Irene Solaiman and AI2's Ali Farhadi will discuss the challenges of open source AI on a panel at TechCrunch Disrupt 2024. They will explore the possibilities and challenges of defining, creating, and providing access to open AI systems, despite the resource requirements of AI models making open source alternatives difficult. Solaiman, Hugging Face's head of global policy, and Farhadi, a proponent of openness and transparency, acknowledge the structural barriers facing the embodiment of these principles in AI. 'It's certain to be an extremely interesting conversation,' according to the TechCrunch article. The panel will take place at Disrupt 2024 in San Francisco from October 28-30.
Original language: en
Publish date: August 27, 2024 03:30 PM
Source:[TechCrunch](https://techcrunch.com/2024/08/27/is-open-source-ai-even-possible-let-alone-the-future-find-out-at-disrupt-2024)

**Mark Zuckerberg Advocates for Open Source AI as Industry Standard**
Mark Zuckerberg, CEO of Meta, has advocated for open-source AI as the future of technology development. He believes that open-source AI models will outpace closed systems by offering greater flexibility, security, and cost efficiency. Zuckerberg highlighted releasing Llama 3.1, a frontier-level open-source AI model, as a significant step towards making open source the industry standard. He argues that open-source AI will be safer, more accessible, and more beneficial in the long term, as it democratizes access to AI technology, prevents power from being concentrated in a few companies, and enhances global security. Zuckerberg's vision is for open-source AI to become the foundation of future technological and economic advancements.
Original language: en
Publish date: August 27, 2024 12:00 PM
Source:[The Software Report](https://www.thesoftwarereport.com/mark-zuckerberg-advocates-for-open-source-ai-as-industry-standard)

**Exploring the Next Frontier with AI: Transforming Space, Earth Science and the Future**
Harvey Nash, NashTech, and the NASA Goddard Space Flight Center are hosting an exclusive event on September 17, 2024, at The Forum, Columbia University, to explore the future of Artificial Intelligence (AI) in space exploration, Earth science, and beyond. The event will feature a U.S. film premiere of the documentary 'AI and Robotics: A Near Future You're Not Prepared For,' followed by a panel discussion led by NASA's Chief AI Officer, Omar Hatamleh. The discussion will cover how AI is revolutionizing space exploration, driving groundbreaking discoveries in Earth science, and shaping the future of our planet and universe. Attendees will have the opportunity to gain insights from NASA, network with fellow technology leaders, and be inspired by the possibilities of AI. 'Don't miss this chance to embark on a journey that transcends the limits of imagination,' said the organizers. 'Secure your spot today!' Space is limited, and registration is available at https://campaign.nashtechglobal.com/nasa-ai-event.
Original language: en
Publish date: August 27, 2024 12:00 PM
Source:[PRWeb](https://www.prweb.com/releases/exploring-the-next-frontier-with-ai-transforming-space-earth-science-and-the-future-302231452.html)

**Apple's AI Gambit May Create New Frontier in Mobile Commerce**
Apple is launching 'Apple Intelligence,' a sweeping artificial intelligence (AI) initiative that could rewrite the rules of digital commerce. The tech giant's push comes as Silicon Valley wages an AI arms race. Apple's AI integration could bring a true AI assistant, something that's portable, convenient and seamlessly integrated into our daily lives, according to Ryan Waite, vice president of public affairs at Think Big. The first iteration of iOS 18 will debut alongside Apple's iPhone 16 models in September, with the full range of AI features slated for the iOS 18.1 update in mid-to-late October. Initial offerings include AI-enhanced writing tools, context-aware reply suggestions in the Messages app, email summarization capabilities and real-time phone call transcription. More advanced features, such as 'Image Playground' and 'Genmoji,' are expected to launch in early 2025. Apple's AI push could revolutionize shopping, reducing friction in the purchasing process and offering hyper-personalized experiences. However, Apple must address a significant challenge: privacy. The company has long positioned itself as the guardian of user data, but AI requires vast amounts of personal information to function effectively, creating tension between AI capabilities and privacy protection.
Original language: en
Publish date: August 26, 2024 07:58 PM
Source:[PYMNTS](https://www.pymnts.com/apple/2024/apples-ai-gambit-may-create-new-frontier-in-mobile-commerce)

**Why Silicon Valley Wants to Kill this AI Bill**
The Safe and Secure Innovation for Frontier Artificial Intelligence Models Act, or SB 1047, has sparked opposition from big tech companies, including Meta, Google, and OpenAI, who claim it will deter AI innovation in California. However, prominent AI researchers, including Yoshua Bengio and Geoffrey Hinton, have come out in support of the bill. The bill requires developers of costly and powerful AI tools to test whether they can enable attacks on public infrastructure or create weapons. It also establishes CalCompute, a public 'cloud' of shared computers, and protects whistleblowers at companies building advanced AI. Whistleblower Daniel Kokotajlo supports the bill, saying it would have prevented or led to the reporting of a safety violation he witnessed at OpenAI. Opponents argue that the bill's AI testing requirements and safety provisions will have a chilling effect on startups and small businesses. Governor Gavin Newsom has not taken a position on the legislation, but has warned against overregulation, saying it could put California in a 'perilous position.' The bill must survive the Assembly Appropriations suspense file and win final approval by August 31 to reach Governor Newsom this year.
Original language: en
Publish date: August 24, 2024 06:13 PM
Source:[Edhat](https://www.edhat.com/news/why-silicon-valley-wants-to-kill-this-ai-bill)

**Generative AI Digest: The debate over open-source vs. closed-source models**
The past month has seen a surge in new large language models from various companies, including OpenAI, Mistral AI, Google, Runway AI, and Meta. Meta's Llama 3.1, a 405 billion-parameter open-source model, has drawn significant attention for its performance comparable to leading closed-source models. However, none of these models are truly open-source, as they require separate licenses for commercial use. The debate between open-source and closed-source models has been influenced by the dominance of leading frontier models, but the release of Llama 3.1 has narrowed the gap, providing organizations with more control over their models. Other notable product and funding announcements include OpenAI's acquisition of Multi Software, Cohere's $500 million series D funding, and Harvey's $100 million funding for its AI-powered legal assistant platform.
Original language: en
Publish date: August 22, 2024 04:00 AM
Source:[S&P Global](https://www.spglobal.com/marketintelligence/en/news-insights/research/generative-ai-digest-the-debate-over-open-source-vs-closed-source-models)

**There's something strange about the latest update to ChatGPT | Digital Trends**
OpenAI has updated its ChatGPT chatbot with a new version of its GPT-4o large language model, but the company has declined to specify exactly how the updated model differs from its predecessor. According to OpenAI, the update is an improvement to GPT-4o, but not a new frontier-class model. The company has not provided specific details on the changes, leading users to speculate about the nature of the update. Some users have suggested that the new model may have implemented a multistep reasoning method, while others have noted that it seems to be behaving in subtly different and better ways. OpenAI has since added a few details to its Models page, including the knowledge cutoff of October 2023 and the ability to accommodate 128,000 tokens per conversation, but the company has not provided any insight into what the new model is actually capable of. 'To be clear, this is an improvement to GPT-4o and not a new frontier model,' OpenAI posted on X. 'We've introduced an update to GPT-4o that we've found, through experiment results and qualitative feedback, ChatGPT users tend to prefer,' the company wrote in its Model Release Notes. 'It's not a new frontier-class model. Although we'd like to tell you exactly how the model responses are different, figuring out how to granularly benchmark and communicate model behavior improvements is an ongoing area of research in itself (which we're working on!).'
Original language: en
Publish date: August 14, 2024 05:48 PM
Source:[Digital Trends](https://www.digitaltrends.com/computing/openai-dropped-new-gpt-4o-wont-say-what-changed/)

**California AI bill SB 1047 aims to prevent AI disasters, but Silicon Valley warns it will cause one | TechCrunch**
California's SB 1047 bill aims to prevent AI disasters by implementing safeguards for large AI models. The bill requires developers to implement safety protocols, including an 'emergency stop' button, and to hire third-party auditors annually to assess their AI safety practices. The bill also establishes a new agency, the Frontier Model Division (FMD), to oversee the rules. Silicon Valley players, including venture capitalists, big tech trade groups, researchers, and startup founders, have opposed the bill, citing concerns about its arbitrary thresholds, chilling effect on the AI ecosystem, and potential harm to open source models. However, AI researchers and safety advocates, such as Geoffrey Hinton and Yoshua Bengio, have supported the bill, citing the need to mitigate the risk of extinction from AI. The bill is expected to pass the California Senate and will be sent to Governor Gavin Newsom's desk for signature.
Original language: en
Publish date: August 13, 2024 04:34 PM
Source:[TechCrunch](https://techcrunch.com/2024/08/13/california-ai-bill-sb-1047-aims-to-prevent-ai-disasters-but-silicon-valley-warns-it-will-cause-one/)

**Why Silicon Valley is trying so hard to kill…**
The Safe and Secure Innovation for Frontier Artificial Intelligence Models Act, Senate Bill 1047, has sparked controversy in California's tech industry. While some, like prominent AI researchers Yoshua Bengio and Geoffrey Hinton, support the bill, others, including Meta and Google, oppose it. The bill aims to regulate artificial intelligence, particularly large language models, and includes provisions for whistleblower protections. Whistleblower Daniel Kokotajlo, a former OpenAI employee, supports the bill, citing concerns about the company's safety protocols and the need for transparency and democratic governance around AI. Kokotajlo believes that the bill would have prevented or led to the prompt reporting of a safety violation he witnessed in 2022. Opponents argue that the bill's restrictions could deter AI innovation in California and hurt the state economy. Supporters, however, say that the bill is necessary to address the risks posed by AI and that the vast majority of startups won't be affected by the bill's restrictions.
Original language: en
Publish date: August 13, 2024 02:49 PM
Source:[East Bay Times](https://www.eastbaytimes.com/2024/08/13/why-silicon-valley-is-trying-so-hard-to-kill-this-ai-bill-in-california)

**Silicon Valley Wants to Kill AI Reform Bill Headed for Committee Vote This Week**
The Safe and Secure Innovation for Frontier Artificial Intelligence Models Act, also known as Senate Bill 1047, is a California legislation that aims to regulate artificial intelligence. The bill has been met with opposition from big tech companies, including Meta, Google, and OpenAI, who claim it will 'deter AI innovation in California at a time where we should be promoting it.' However, prominent AI researchers, including Yoshua Bengio and Geoffrey Hinton, have come out in support of the bill. The bill would require developers of costly and powerful AI tools to test whether they can enable attacks on public infrastructure or create weapons. It would also establish a public 'cloud' of shared computers to conduct research into safe and secure AI deployment. Whistleblower protections are also included in the bill, which would allow employees to report AI models that are capable of causing critical harm without fear of retaliation. Open source defenders have voiced opposition to the bill, claiming it would have a chilling effect on the release of AI models and tools. However, supporters argue that the bill is necessary to protect tech workers and hold companies accountable for the effects of their products.
Original language: en
Publish date: August 12, 2024 08:21 PM
Source:[San Jose Inside](https://www.sanjoseinside.com/news/silicon-valley-wants-to-kill-ai-reform-bill-headed-for-committee-vote-this-week)

**Why Silicon Valley wants to kill this AI bill**
The Safe and Secure Innovation for Frontier Artificial Intelligence Models Act, or SB 1047, has sparked opposition from big tech companies, startup founders, and investors in California. The bill, which aims to regulate artificial intelligence, would require developers of costly and powerful AI tools to test whether they can enable attacks on public infrastructure or create chemical, biological, radioactive, or nuclear weapons. It would also establish a public 'cloud' of shared computers to foster the equitable development of technology and protect whistleblowers at companies building advanced forms of AI. Opponents argue that the bill's AI testing requirements and safety provisions would deter innovation and hurt the state economy. Supporters, including prominent AI researchers and whistleblower Daniel Kokotajlo, say the bill is necessary to protect tech workers and society from the potential harms of AI. Kokotajlo, who quit his job at OpenAI due to concerns about the company's safety protocols, believes that the bill would have prevented or led to the reporting of a safety violation he witnessed in 2022. OpenAI spokesperson Liz Bourgeois said the company's whistleblower policy protects employees' rights to raise issues, but Kokotajlo and others argue that existing protections are insufficient. The bill has sparked a backlash from tech firms, which are not used to being held responsible for the effects of their products. Governor Gavin Newsom has not taken a position on the legislation, but has advised lawmakers against overreach, saying that California should remain an AI leader while also protecting society.
Original language: en
Publish date: August 12, 2024 07:58 PM
Source:[Times-Standard](https://www.times-standard.com/2024/08/12/why-silicon-valley-wants-to-kill-this-ai-bill)

**OpenAI will not be announcing its next major frontier model at DevDay 2024**
OpenAI has announced DevDay 2024, a series of developer conferences in San Francisco, London, and Singapore. The events will take place on October 1, October 30, and November 21, respectively. According to OpenAI, 'This year, we're bringing the OpenAI DevDay experience closer to our global developer community.' However, OpenAI has confirmed that they will not be revealing their next major frontier model at the event. Instead, the focus will be on improving the API and dev tools, with workshops, breakout sessions, demos, developer spotlights, and an evening reception. Interested developers can apply to attend before August 15, with a registration fee of $450. Limited scholarships are also available.
Original language: en
Publish date: August 06, 2024 03:24 AM
Source:[Neowin](https://www.neowin.net/news/openai-will-not-be-announcing-its-next-major-frontier-model-at-devday-2024/)

**Microsoft: Buy, Despite Closed-Source Frontier AI Limiting Growth (NASDAQ:MSFT)**
Microsoft's (MSFT) recent Q4 earnings report showed a 21% YoY increase in Microsoft Cloud revenue and a 29% YoY increase in Azure and Cloud Services revenue. This growth is attributed to the company's AI efforts and direction towards developing AGI. However, the company's closed-source approach to frontier models, such as those developed by OpenAI, may limit its growth. Analysts believe that Microsoft's reliance on OpenAI's models may be a temporary advantage, and that the company may eventually develop its own AGI moat. Microsoft's significant investment in AI infrastructure, including a $19B capex in Q4, is expected to yield benefits in the long term. The company's partnership with OpenAI is seen as a way to bolster its AI ecosystem, but some analysts believe that Microsoft may be able to develop its own AGI in advance of OpenAI. Microsoft's stock is currently fairly valued, with a 5Y price target of $817.50 in August 2029, based on a 15% price CAGR over the next 5 years.
Original language: en
Publish date: August 05, 2024 04:30 PM
Source:[Seeking Alpha](https://seekingalpha.com/article/4710529-microsoft-buy-despite-closed-source-frontier-ai-limiting-growth)

**Meta Just Launched The Largest ‘open' AI Model In History. Here's Why It Matters**
Meta, the parent company of Facebook, has released the largest 'open' AI model in history, Llama 3.1 405B, which is a large language model capable of generating human language text in multiple languages. According to Meta's founder and chief executive, Mark Zuckerberg, this is 'the first frontier-level open source AI model'. While this is good news for those who care about a future in which everybody can access the benefits of AI, there are also risks and ethical concerns associated with open-source AI, such as the potential for low quality control, cyberattacks, and misuse. However, open-source AI also allows for scrutiny and identification of potential biases and vulnerabilities, and can be leveraged without the immense resources required to train large language models from scratch. To ensure AI is democratised, three key pillars are needed: governance, accessibility, and openness. Achieving these pillars is a shared responsibility for government, industry, academia, and the public, and requires addressing questions such as how to balance protecting intellectual property and fostering innovation through open-source AI, and how to safeguard open-source AI against potential misuse.
Original language: en
Publish date: August 05, 2024 07:15 AM
Source:[Stuff South Africa](https://stuff.co.za/2024/08/05/meta-launched-the-largest-open-ai-model-in)

**Meta just launched the largest ‘open' AI model in history. Here's why it matters**
Meta has released the largest 'open' AI model in history, Llama 3.1 405B, which is a large language model capable of generating human language text in multiple languages. According to Meta's founder and CEO Mark Zuckerberg, this model is 'the first frontier-level open source AI model'. While it is considered highly competitive and performs better than existing closed-source models in certain tasks, it is not fully open as the huge data set used to train it has not been released. This model levels the playing field for researchers, small organisations and startups by allowing them to leverage it without the immense resources required to train large language models from scratch. However, open-source AI also creates new risks and ethical concerns, such as low quality control, potential biases, and vulnerability to cyberattacks. To ensure AI is democratised, three key pillars are needed: governance, accessibility, and openness. Achieving these pillars is a shared responsibility for government, industry, academia and the public.
Original language: en
Publish date: August 04, 2024 11:42 AM
Source:[Hindustan Times](https://tech.hindustantimes.com/tech/news/meta-just-launched-the-largest-open-ai-model-in-history-here-s-why-it-matters-71722695907515.html)

**AI Model Deployed to International Space Station for Mission-Critical Solutions**
The American company Booz Allen Hamilton, specializing in intelligence and counterintelligence in the field of electronic services, placed a large language model (LLM) on the International Space Station in January. The platform, equipped with a 130-terabyte SSD storage device from KIOXIA, is expected to reduce the volume of data transmitted to Earth by 30,000 times. According to Booz Allen Hamilton, 'This is indeed a new frontier for generative AI, and this capability opens up the potential for generative AI in orbit for integration and development of critical mission-critical solutions.' The developed model, created in less than eight weeks, will help crews on the front line by efficiently providing necessary information, understanding tasks, and solving complex problems using natural language processing.
Original language: ru
Publish date: August 04, 2024 10:32 AM
Source:[24 Канал](https://24tv.ua/tech/ru/na-mks-zarabotal-ii-kotoryj-pomozhet-preodolet-bolshie-obemy-nauchnyh-dannyh-tehno_n2611194)

**World News | Meta Just Launched the Largest 'open' AI Model in History. Here's Why It Matters | LatestLY**
Meta, the parent company of Facebook, has released a new collection of large AI models, including Llama 3.1 405B, which is 'the first frontier-level open source AI model', according to Mark Zuckerberg. This is a significant step towards open-source AI, which allows for transparency and community collaboration. Open-source AI models are not proprietary and can be audited by regulators, whereas closed-source AI models are not transparent and can be used for malicious purposes. Llama 3.1 405B is the largest open-source AI model in history and can be downloaded online, but it does not outperform other models across all metrics. However, it is considered highly competitive and performs better than existing closed-source and commercial large language models in certain tasks. The future of AI depends on three key pillars: governance, accessibility, and openness, and the public can play a vital role by advocating for ethical policies in AI and supporting open-source AI initiatives.
Original language: en
Publish date: August 03, 2024 03:59 AM
Source:[LatestLY](https://www.latestly.com/agency-news/world-news-meta-just-launched-the-largest-open-ai-model-in-history-heres-why-it-matters-6160119.html)

**Meta Just launched the Largest ‘Open' AI Model in History. Here's Why It Matters.**
Meta, the parent company of Facebook, has released the largest 'open' AI model in history, Llama 3.1 405B, which is considered a frontier-level open-source AI model. This move is significant as it allows for community collaboration, scrutiny, and identification of potential biases and vulnerabilities. However, open-source AI also creates new risks and ethical concerns, such as low quality control and the potential for malicious use. Meta's move is seen as a step towards democratizing AI and ensuring that it serves the greater good. The article highlights the importance of three key pillars for achieving this goal: governance, accessibility, and openness. It also raises questions about how to balance protecting intellectual property and fostering innovation through open-source AI, and how to minimize ethical concerns and safeguard against potential misuse.
Original language: en
Publish date: August 02, 2024 08:32 PM
Source:[Singularity Hub](https://singularityhub.com/2024/08/02/meta-just-launched-the-largest-open-ai-model-in-history-heres-why-it-matters)

**Meta Just Launched the Largest ‘Open' AI Model in History. Here's Why It Matters.**
Meta, the parent company of Facebook, has released the largest 'open' AI model in history, named Llama 3.1 405B. According to Meta's founder and CEO, Mark Zuckerberg, this model is 'the first frontier-level open-source AI model.' The model is a large language model that can generate human language text in multiple languages and can be downloaded online. However, it does not outperform other models across all metrics and Meta has not released the huge dataset used to train it. The release of this model is seen as a step towards democratizing AI and making it more accessible to researchers, small organizations, and startups. However, open-source AI also creates new risks and ethical concerns, such as low quality control and potential biases. To ensure AI is democratized, three key pillars are needed: governance, accessibility, and openness. The public can play a vital role by advocating for ethical policies in AI, staying informed about AI developments, using AI responsibly, and supporting open-source AI initiatives.
Original language: en
Publish date: August 02, 2024 08:32 PM
Source:[Zephyrnet](https://zephyrnet.com/meta-just-launched-the-largest-open-ai-model-in-history-heres-why-it-matters)

**What in the AI is going on... April to June 2024**
Meta launched its newest generation of its open-source LLM, Llama 3, which is the technology that powers its AI systems. OpenAI also discussed plans for its next AI model, GPT-5. Lawhive, a London-based legal tech start-up, received £9.5m investment from Google to expand its software development team and improve its AI system, Lawrence. The UK's Digital Regulation Cooperation Forum (DCRF) launched its new AI and Digital Hub to provide free and informal advice to UK businesses developing new AI products or services. Reddit issued a strong warning that it will bring legal action against AI providers that are found using data from its platform without permission. Wayve, a British AI company, received $1 billion of investment from SoftBank Group, Nvidia, and Microsoft to develop its 'embodied AI' technology for self-driving vehicles. Sony Music became the latest company to warn AI firms to stop using its data without permission. The ICO raised privacy concerns over Microsoft's forthcoming feature 'Recall'. The UK Government co-hosted the AI Seoul Summit with the Republic of Korea, where 16 companies agreed to follow voluntary safety commitments when developing frontier AI. AI start-up, xAI, owned by Elon Musk, Nvidia, Supermicro, and Dell, partnered up to work on a project to build the world's largest supercomputer. Adobe issued a statement to clarify how it uses user data, confirming that user data remains under ownership of the user. Waabi, an AI company based in Canada, received $200 million from a funding round to achieve its goal to have self-driving trucks powered by generative AI on the roads of Texas by 2025.
Original language: en
Publish date: August 02, 2024 01:44 PM
Source:[Lexology](https://www.lexology.com/library/detail.aspx?g=d204e6c5-5f3f-493d-9ebe-1a1ac550a1a6)

**Meta Just Launched The Largest 'Open' AI Model In History. Heres Why It Matters**
Meta, the parent company of Facebook, has released the largest 'open' AI model in history, Llama 3.1 405B. This model is considered a 'frontier-level open-source AI model' by Meta's founder and CEO, Mark Zuckerberg. The release of this model is seen as a step towards making AI technology more accessible and transparent. However, some concerns remain about the potential risks and ethical implications of open-source AI, including the lack of quality control and the potential for misuse. Despite these concerns, Meta's move is seen as a positive step towards democratizing AI and ensuring that it serves the greater good.
Original language: en
Publish date: August 02, 2024 08:00 AM
Source:[NDTV](https://www.ndtv.com/india-ai/meta-just-launched-the-largest-open-ai-model-in-history-heres-why-it-matters-6246346)

**Meta just launched the largest 'open' AI model in history: here's why it matters**
Meta, the parent company of Facebook, has released a new collection of large AI models, including Llama 3.1 405B, which is 'the first frontier-level open source AI model', according to Meta's founder and chief executive, Mark Zuckerberg. This move is seen as a significant step towards open-source AI, which allows for transparency, community collaboration, and scrutiny of potential biases and vulnerabilities. However, open-source AI also creates new risks and ethical concerns, such as low quality control and potential for malicious use. Meta's Llama 3.1 405B is considered highly competitive and performs better than existing closed-source and commercial large language models in certain tasks, but it is not fully open as the huge data set used to train it has not been released. To ensure AI is democratised, three key pillars are needed: governance, accessibility, and openness. Achieving these pillars is a shared responsibility for government, industry, academia, and the public.
Original language: en
Publish date: August 02, 2024 07:21 AM
Source:[Economic Times](https://economictimes.indiatimes.com/tech/artificial-intelligence/meta-just-launched-the-largest-open-ai-model-in-history-heres-why-it-matters/articleshow/112217092.cms)

**Meta just launched the largest 'open' AI model in history. Here's why it matters**
Meta, the parent company of Facebook, has released a new collection of large AI models, including Llama 3.1 405B, which is 'the first frontier-level open source AI model', according to Meta's founder and chief executive, Mark Zuckerberg. This move is seen as a significant step towards open-source AI, which allows for transparency, community collaboration, and scrutiny of potential biases and vulnerabilities. However, open-source AI also creates new risks and ethical concerns, such as low quality control and potential for cyberattacks. The new model is considered highly competitive and performs better than existing closed-source and commercial large language models in certain tasks, but it is not fully open as Meta hasn't released the huge data set used to train it. To ensure AI is democratised, three key pillars are needed: governance, accessibility, and openness. Achieving these pillars is a shared responsibility for government, industry, academia, and the public.
Original language: en
Publish date: August 01, 2024 08:28 PM
Source:[The Conversation](http://theconversation.com/meta-just-launched-the-largest-open-ai-model-in-history-heres-why-it-matters-235689)

**GPT-5: The Next Frontier in the AI Arms Race**
The tech world is eagerly awaiting the release of GPT-5, the next iteration of OpenAI's groundbreaking language model. According to Hamish Low of Enders Analysis, 'If OpenAI can deliver technology that matches its ambitious vision for what AI can be, it will be transformative for its own prospects, but also the economy more broadly.' However, the stakes are high, and OpenAI must continue to push the boundaries of AI to justify its investment and maintain its leadership position. The company faces a daunting challenge in delivering a superior product while addressing growing concerns about AI's impact on society, such as bias, misinformation, and job displacement. The outcome of GPT-5's release will shape the future of AI for years to come.
Original language: en
Publish date: July 31, 2024 04:39 AM
Source:[PhoneWorld](https://www.phoneworld.com.pk/gpt-5-the-next-frontier-in-the-ai-arms-race)

**Meta Platforms Just Released an Artificial Intelligence (AI) Game-Changer -- And It Could Be Dangerous | The Motley Fool**
Meta has released its Llama 3.1 model, a frontier AI model with 405 billion parameters, which outperforms other models on many parameters. The model is open-source, allowing developers to modify and improve it. Mark Zuckerberg believes this will make Meta the world's most-used AI assistant by the end of the year, surpassing OpenAI. However, there are risks to open-source AI, including privacy and security concerns, which may lead to government scrutiny and regulation. Zuckerberg argues that these risks are outweighed by the benefits of open innovation, but the approach may still face challenges.
Original language: en
Publish date: July 28, 2024 02:40 PM
Source:[The Motley Fool](https://www.fool.com/investing/2024/07/28/meta-platforms-ai-llama-3-point-1-game-changer/)

**AI is approaching an open-source inflection point**
Meta's open-source Llama models have reached an important threshold, with the latest model achieving 'frontier-level' status, comparable to the most powerful AI from companies like OpenAI, Google, and Anthropic. According to Mark Zuckerberg, future Llama models will surpass others to become the world's most advanced from 2025.
Original language: en
Publish date: July 27, 2024 09:21 AM
Source:[The Straits Times](https://www.straitstimes.com/opinion/ai-is-approaching-an-open-source-inflection-point)

**Silicon Valley shaken as open-source AI models Llama 3.1 and Mistral Large 2 match industry leaders**
The open-source AI models Llama 3.1 and Mistral Large 2 have reached a frontier-level status, matching industry leaders like OpenAI, Google, and Anthropic. This democratization of cutting-edge AI capabilities is expected to accelerate innovation globally, potentially reshaping entire industries and altering the balance of power in the tech world. However, it also raises new challenges, including the need for organizations to develop strategies that leverage these open technologies while adding unique value, and the need for policymakers to create adaptive regulatory frameworks to ensure public safety and ethical use of AI.
Original language: en
Publish date: July 27, 2024 01:45 AM
Source:[DNyuz](https://dnyuz.com/2024/07/26/silicon-valley-shaken-as-open-source-ai-models-llama-3-1-and-mistral-large-2-match-industry-leaders)

**Memo on AI's national-security implications heads for Biden's desk**
President Joe Biden is expected to receive a classified memo outlining the national-security implications of AI and suggesting limits to its deployment. The memo, ordered by Biden's October executive order on AI, aims to develop a coordinated executive-branch approach to managing AI's security risks. The memo will focus on national security systems in military and intelligence agencies, as well as some FBI and DHS systems, and will likely carry significant implications for cloud service providers and frontier model developers. The memo will also address securing U.S. leadership in AI innovation and standardization, talent development, energy demands of AI computing, and prohibited and high-impact uses of AI systems.
Original language: en
Publish date: July 26, 2024 04:00 PM
Source:[Defense One](https://www.defenseone.com/threats/2024/07/biden-receive-ai-national-security-memo-outlining-forbidden-uses-areas-innovation/398382)

**Google, Microsoft, and OpenAI Launch Coalition for Secure AI**
Google, Microsoft, and OpenAI have launched a new coalition to focus on the security of artificial intelligence (AI). The Coalition for Secure AI (CoSAI) framework will operate as an open-source group, sharing methods, standards, and tools. Founding members include Anthropic, Amazon, Cisco, Google, IBM, Intel, Microsoft, Nvidia, and PayPal. Co-chairs are David LaBianca, senior director at Google, and Omar Santos, engineer and AI security researcher at Cisco. CoSAI will collaborate with the US National Institute of Standards and Technology (NIST), Open-Source Security Foundation (OpenSSF), and other stakeholders, conducting joint research. Additionally, CoSAI will work with organizations such as Frontier Model Forum, Partnership on AI, OpenSSF, and ML Commons. CoSAI will be housed at OASIS Open, the international standards and open-source consortium.
Original language: nl
Publish date: July 26, 2024 07:00 AM
Source:[Emerce](https://www.emerce.nl/nieuws/google-microsoft-openai-anderen-lanceren-coalitie-veilige-ai)

**Mark Zuckerberg Advocates For Open-source AI As Meta Launches Llama 3.1**
Meta CEO Mark Zuckerberg has advocated for open-source AI, calling it a 'way ahead' for the sector. The company has released Llama 3.1, the first 'frontier-level open-source AI model', which can converse in multiple languages, write higher-quality computer code, and solve more complex math problems. Zuckerberg believes that open-source AI will become the industry standard, citing the evolution of open-source software Linux as an example. He also highlighted the benefits of open-sourcing, including customization, independence from closed vendors, data protection, and cost-efficiency benefits for developers. Zuckerberg stated that Meta will benefit from open-sourcing, ensuring access to the best technology and avoiding lock-ins to competitors' ecosystems.
Original language: en
Publish date: July 24, 2024 03:05 PM
Source:[TechBullion](https://techbullion.com/mark-zuckerberg-advocates-for-open-source-ai-as-meta-launches-llama-3-1)

**Meta Unveils Llama 3.1 405B, a Frontier AI Model Challenging GPT-4 and Claude 3.5 Sonnet**
Meta has released Llama 3.1 405B, an open-source AI model that challenges GPT-4 and Claude 3.5 Sonnet. According to Meta, led by Mark Zuckerberg, Llama 3.1 405B is the first open-source model capable of competing with the best AI models in terms of advanced capabilities in general knowledge, governance, mathematics, tool use, and multilingual translation. 'We believe that the latest generation of Llama will enable new applications and modeling paradigms, including the generation of synthetic data to enable the improvement and training of smaller models, as well as model distillation, a capability that has never been achieved on this scale in open source.' The model is available for download on llama.meta.com and Hugging Face. Meta has evaluated the performance of Llama 3.1 on over 150 test datasets covering a wide range of languages. Additionally, it has conducted in-depth human evaluations to compare Llama 3.1 with competing models in real-world scenarios. 'Our experimental evaluation', reads the blog post, 'indicates that our top model is competitive with the main base models in a series of tasks, including GPT-4, GPT-4o, and Claude 3.5 Sonnet. Moreover, our smaller models are competitive with closed and open models with a similar number of parameters.' Meta has optimized the entire training stack and pushed the training of the model on over 16,000 GPU H100, making 405B 'the first Llama model trained on this scale'.
Original language: it
Publish date: July 24, 2024 06:01 AM
Source:[Hardware Upgrade](https://www.hwupgrade.it/news/web/meta-svela-llama-31-405b-il-suo-nuovo-modello-ia-di-frontiera-che-sfida-gpt-4o-e-claude-35-sonnet_129156.html)

**Mark Zuckerberg calls for open-source AI as Meta releases Llama 3.1**
Meta CEO Mark Zuckerberg has called for open-source artificial intelligence, stating that it will become the industry standard. He believes that AI will follow a similar path to open-source software, with closed models initially leading but open-source eventually catching up. The company has released Llama 3.1, a 'frontier-level open-source AI model' that can converse in multiple languages, write higher-quality code, and solve complex math problems. Zuckerberg expects future Llama models to become the most advanced in the industry, and believes that open-source AI will provide benefits such as customization, independence from closed vendors, data protection, and cost-efficiency. He also argues that open-source AI can be safer due to transparency and wider scrutiny, and that it will be strategically advantageous for the United States and its allies. Zuckerberg concludes that open-source AI will ensure that more people have access to AI benefits, power isn't concentrated in a few companies, and the technology can be deployed more evenly and safely.
Original language: en
Publish date: July 24, 2024 05:32 AM
Source:[Cointelegraph](https://cointelegraph.com/news/mark-zuckerberg-calls-open-source-meta-releases-llama-3-1)

**Meta unveils latest artificial intelligence models as it plans open source future**
Meta has unveiled the latest version of its artificial intelligence models, including Llama 3.1 405B, which will be the first 'frontier-level' open source AI model. The company will also release upgraded Llama 3.1 70B and 8B models. According to Meta's CEO Mark Zuckerberg, this move marks a significant step forward in the development of AI technology.
Original language: en
Publish date: July 23, 2024 06:14 PM
Source:[World News Network](https://article.wn.com/view/2024/07/23/Meta_unveils_latest_artificial_intelligence_models_as_it_pla)

**Elon Musk Establishes World's Most Powerful AI Training Cluster**
Elon Musk, the CEO of various companies including Tesla, SpaceX, Starlink, X (formerly Twitter), Neuralink, and xAI, has announced the establishment of the world's most powerful artificial intelligence training cluster, called Memphis Supercluster. The cluster is composed of 100,000 liquid-cooled Nvidia H100 GPUs connected via a single RDMA (remote direct memory access) network. Musk aims to use this cluster to train the most advanced artificial intelligence. The cluster is expected to be completed by December and will be used to train the next versions of xAI's language model, Grok. The current version, Grok 1.5, has already been released, and Grok 2 is expected to be released in the coming months. Musk has also announced that Grok 3 will be released in late 2024. The Memphis Supercluster is expected to surpass the processing power of the world's top supercomputers, including Frontier, Aurora, and Microsoft Eagle.
Original language: tr
Publish date: July 23, 2024 07:52 AM
Source:[DonanımHaber](https://www.donanimhaber.com/elon-musk-dunyanin-en-guclu-yapay-zeka-egitim-kumesini-kurdu--179774)

**AI's new frontier: Hugging Face, Nvidia, and OpenAI lead charge in small language models**
Three major players in artificial intelligence, Hugging Face, Nvidia, and OpenAI, have released small language models (SLMs) that promise to democratize access to advanced natural language processing capabilities. These compact models, SmolLM, Mistral-Nemo, and GPT-4o Mini, each represent different approaches to creating more accessible AI, but they all share a common goal: bringing powerful language processing capabilities to a wider range of devices and applications. This shift towards smaller models reflects a broader trend in the AI community, shifting from a preoccupation with raw capabilities to a more nuanced understanding of real-world applicability.
Original language: en
Publish date: July 19, 2024 09:08 PM
Source:[VentureBeat](https://venturebeat.com/ai/ais-new-frontier-hugging-face-nvidia-and-openai-lead-charge-in-small-language-models)

**Inside the fight over California's new AI bill**
California state Senator Scott Wiener has introduced a bill, SB 1047, requiring companies training 'frontier models' that cost more than $100 million to do safety testing and be able to shut off their models in the event of a safety incident. The bill has sparked fury from the tech industry, with VC heavyweights Andreessen-Horowitz and Y Combinator publicly condemning the bill. Wiener spoke with Kelsey Piper about the challenges to the bill, including concerns about liability, open source developers, and the potential impact on innovation. He emphasized that the bill is a light-touch regulation and that it does not require a license or strict liability. He also addressed concerns about the shutdown provision and fine-tuning, making amendments to address these issues. Wiener believes that the bill will promote responsible deployment and training of AI models, and that it is not intended to eliminate risk, but rather to ensure that risks are understood and mitigated.
Original language: en
Publish date: July 19, 2024 01:00 PM
Source:[Vox](https://www.vox.com/future-perfect/361562/california-ai-bill-scott-wiener-sb-1047)

**OpenAI introduces GPT-4o mini, its cheaper and lighter model for developers**
OpenAI has introduced GPT-4o Mini, a cheaper and lighter AI model for developers. The new model is priced at 15 cents per million input tokens and 60 cents per million output tokens, making it more affordable than earlier frontier models and over 60% cheaper than GPT-3.5 Turbo. GPT-4o Mini can perform a range of tasks, including applications that link multiple model calls, pass on large volumes of context to the model, or interact with customers through fast, real-time text responses via support chatbots. The model supports text and vision in the API and has a context window of 128K tokens, supports up to 16K output tokens, and has knowledge of up to October 2023. OpenAI claims that the new model has surpassed GPT-3.5 Turbo and other small models' academic benchmarks across both multimodal reasoning and textual intelligence.
Original language: en
Publish date: July 19, 2024 04:43 AM
Source:[The Indian Express](https://indianexpress.com/article/technology/artificial-intelligence/gpt-4o-mini-openai-cheaper-ai-model-9462747)

**OpenAI Releases GPT-4o Mini, a Cheaper Version of Flagship AI Model**
OpenAI has released GPT-4o mini, a more affordable and smaller version of its flagship AI model, GPT-4o. The new model is available for free users, paying ChatGPT Plus and Team subscribers, and will be offered to enterprise customers next week. GPT-4o mini offers some of the same functionality as GPT-4o, including text and image generation, and will eventually be able to process other types of content. OpenAI's head of product, Olivier Godement, said the company wants to have the best small models out there, in addition to pushing the envelope with frontier models. The new model uses a new safety tactic called 'instruction hierarchy' to prioritize certain instructions over others.
Original language: en
Publish date: July 18, 2024 02:40 PM
Source:[Yahoo](https://finance.yahoo.com/news/openai-releases-gpt-4o-mini-144035122.html)

**New California AI bill threatens to cripple U.S. innovation**
California legislators are close to passing a bill, Senate Bill 1047, which would stifle innovation and competition in artificial intelligence (AI) development. The bill would require permission from the state at every turn, treating new AI models as dangerous until certified otherwise. This would lead to a regulatory regime that forces technology to advance at the pace of bureaucracy, squashing innovation. The bill would also create a new regulatory agency, the Frontier Model Division (FMD), which would have sweeping authority to define what AI models are 'reasonably able to cause or enable a critical harm'. The FMD would also be able to fund itself via fees levied on companies seeking approval, effectively a tax on new AI models. The bill would cripple the development and dissemination of new open-source AI models, and would likely lead to the creation of AI monopolies. The author argues that the bill ignores the revolutionary benefits that AI may provide and that regulating AI applications based on a rational assessment of risk rather than fear of the technology itself is necessary for the United States to realize these benefits and be competitive with the rest of the world.
Original language: en
Publish date: July 14, 2024 12:55 PM
Source:[San Bernardino Sun](https://www.sbsun.com/2024/07/14/new-california-ai-bill-threatens-to-cripple-u-s-innovation)

**Apple and Microsoft Resign from OpenAI's Board of Directors Amid Ongoing Investigations**
Microsoft and Apple have resigned from their positions on OpenAI's board of directors. Microsoft's decision was made through a letter stating that it would take effect immediately. Apple had previously agreed to take a seat on the board, but ultimately decided not to. OpenAI will replace the two positions with periodic meetings with partners like Microsoft, Apple, and investors Thrive Capital and Khosla Ventures. Experts believe the change is related to ongoing investigations by the European Union and the United States into the development, implementation, and investments in AI projects. The article also mentions the creation of the Frontier Model Forum and the AI Safety Institute, which aim to ensure the safe and responsible development of AI models. The dispute between ethics and commerce is ongoing, with the market value of AI software estimated to reach $126 billion by 2025.
Original language: es
Publish date: July 11, 2024 12:59 AM
Source:[Xataka México](https://www.xataka.com.mx/robotica-e-ia/apple-microsoft-renuncian-a-sus-puestos-junta-directiva-openai-jugada-maestra-para-saltar-a-vigilantes)


