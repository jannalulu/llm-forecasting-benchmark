2024-11-07 13:07:37,222 - INFO - Question: Before December 1, 2024, will laws be in place requiring that AI systems that emulate humans must reveal to people that they are AI?

2024-11-07 13:07:37,222 - INFO - News articles for question 29636:
Here are the relevant news articles:

**A View From California: One Important Artificial Intelligence Bill Down, 17 Others Good To Go**
California has passed 18 bills related to Artificial Intelligence (AI), with 17 of them going into effect on January 1, 2026. The bills cover various aspects of AI, including transparency, accountability, and regulation. The California AI Transparency Act requires providers of publicly accessible AI systems to disclose when content has been generated or modified by AI. The Artificial Intelligence Training Data Transparency Act mandates that developers of generative AI systems publicly disclose information about the data used to train their models. The Generative Artificial Intelligence Accountability Act requires the California Office of Emergency Services to conduct a risk analysis of potential threats posed by generative AI. Other bills address issues such as AI in healthcare, consumer privacy, and telecommunications. Governor Newsom vetoed Senate Bill 1047, which aimed to prevent 'critical harms' associated with AI, citing concerns about the high quantitative thresholds outlined in the bill. The veto may lead to similar proposals in future legislative sessions. Colorado and Utah have also enacted laws related to AI, with Colorado's Senate Bill 205 mandating that developers and deployers of high-risk AI systems take reasonable care to prevent algorithmic discrimination, and Utah's Senate Bill 149 establishing a regulatory framework for the development, deployment, and use of AI technologies within Utah.
Original language: en
Publish date: November 06, 2024 12:00 AM
Source:[jdsupra.com](https://www.jdsupra.com/legalnews/a-view-from-california-one-important-8750570/)

**The Paralyzing Scientific Fact that will Happen in 2045 and Change the World Completely**
According to experts in technology, artificial intelligence (AI) will equal human intelligence by 2029. However, this is not the only prediction, as they also claim that in 21 years, humans will be able to merge with computers and achieve 'singularity'. Raymond Kurzweil, Google's director of engineering, states that we will reach singularity by 2045. This term can be defined as a point in space-time where natural laws do not apply or are uncertain, like inside a black hole. The fusion could be developed through nanobots that will enter the brain through capillaries, allowing people to search and access information instantly and unconsciously, similar to having a smartphone in their head. As a result, AI will begin to expand on a large scale.
Original language: es
Publish date: November 05, 2024 08:01 PM
Source:[El Heraldo de M�xico](https://heraldodemexico.com.mx/tecnologia/2024/11/5/el-paralizante-hecho-cientifico-que-sucedera-en-2045-que-cambiara-el-mundo-por-completo-651200.html)

**# Essential Guidelines for Safely Implementing Generative AI: Key Steps for Effective Governance**
Generative AI, which can create new content such as text, images, and music, has seen rapid advancements. However, its deployment must be carefully governed to ensure safety, ethical use, and compliance with legal standards. Essential guidelines for safely implementing generative AI include understanding its capabilities and limitations, establishing clear objectives and use cases, and addressing bias and fairness, accuracy and reliability, and ethical concerns. According to experts, it is crucial to define the purpose of the AI, such as enhancing creativity or automating repetitive tasks, to guide the development and deployment process. 'The ability to generate realistic content raises ethical questions, such as the potential for misuse in creating fake news, deepfakes, or other forms of disinformation,' said experts. 'Generative AI models are powerful, but they are not infallible. They can generate highly realistic content, but they can also produce biased, misleading, or harmful outputs.'
Original language: en
Publish date: November 05, 2024 05:02 PM
Source:[zephyrnet.com](https://zephyrnet.com/4026569-2/)

**In 2024, the Powerful Potential of AI Took Hold**
In 2024, the potential of AI in government has become more evident, with innovative applications emerging in areas like emergency response, citizen services, and wildfire detection. However, the growing realization of AI's potential risks has also led to the creation of task forces and councils to establish guidelines and policies for its use. The GovAI Coalition, founded in San Jose in late 2023, has grown rapidly with over 350 agencies as members, offering resources like AI fact sheets and use case templates. Meanwhile, agencies are pushing for accountability through measures like AI inventories and dedicated AI leadership positions. However, experts warn that without thorough data governance and hygiene, AI initiatives risk becoming expensive failures. The year has also seen concerns about AI's darker side, including amplified cyber attacks and a potential digital divide. Governments are playing a crucial role in addressing these concerns, with public libraries offering workshops and resources to empower citizens to understand and harness AI's potential.
Original language: en
Publish date: November 05, 2024 12:00 AM
Source:[govtech.com](https://www.govtech.com/artificial-intelligence/in-2024-the-powerful-potential-of-ai-took-hold)

**Webinar: EU AI Regulation in Human Resources**
The integration of Artificial Intelligence (AI) in human resources offers significant potential, but also raises substantial legal and ethical challenges. Our seminar 'KI-Verordnung im Personalwesen' on December 9-10, 2024, will provide valuable strategies for a legally secure implementation of the EU AI Regulation (KI-VO). The seminar will cover the following topics: an overview of the KI-VO, requirements for high-risk AI systems, liability issues, data protection and bias avoidance, risk management in HR departments, and best practices for the lawful and responsible use of AI in HR. Participants will learn what to consider when implementing and using AI in HR management to ensure compliance and transparency. A special focus will be on identifying and managing risks associated with high-risk AI systems. We look forward to your participation and to an inspiring exchange!
Original language: de
Publish date: October 30, 2024 01:05 PM
Source:[openpr.com](https://www.openpr.de/news/1270870/Webinar-KI-Verordnung-im-Personalwesen-9-10-Dezember-2024.html)

**AI back in the regulatory spotlight: California passes new legislation**
California has passed new legislation aimed at regulating the development and use of artificial intelligence ('AI'). Two key bills, SB 942 and AB 2013, will take effect on January 1, 2026. SB 942 requires providers of generative AI systems to disclose metadata associated with AI-generated content, including the name of the provider, the name and version number of the GenAI system, the time and date the content was created or altered, and a unique identifier. AB 2013 requires developers of generative AI systems to post documentation on their website about the data used to train their systems. The bills aim to promote greater transparency from companies working in the AI field, allowing users to knowingly interact with AI-generated content and make informed choices. Companies subject to these laws may need to review their practices by December 31, 2025, to ensure compliance. 'Covered providers' must make tools available at no cost to users of AI systems to determine whether image, video or audio content has been created or altered by an AI system. 'Latent disclosure' refers to metadata associated with AI-generated content, while 'manifest disclosure' requires users to be informed that the content was created by an AI in a clear and conspicuous manner. 'Developers' must post documentation about the data used to train their generative AI systems, including exceptions for substantial modifications made before January 1, 2022. The rapid growth of AI-generated content poses numerous challenges, including the increasing difficulty for consumers to distinguish this type of content from human-created content. California aims to promote greater transparency from companies working in this field so that users can knowingly interact with AI-generated content and make informed choices. 'A covered provider that violates the requirements set out in the bill will be liable to a fine of $5,000 per violation.'
Original language: en
Publish date: October 28, 2024 12:51 PM
Source:[Lexology](https://www.lexology.com/library/detail.aspx?g=8fe6b6ed-cdca-4d6c-b306-6acf66bf4ace)

**European Union Introduces New Law to Regulate Artificial Intelligence**
The European Union has introduced a new law, (UE) 2024/1689, to regulate artificial intelligence (AI) and ensure its safe and responsible use. The law aims to protect individuals and society from potential risks, while promoting digital innovation and transparency. It defines AI as 'systems that use algorithms to analyze data and make decisions' and categorizes systems into three types: low-risk, high-risk, and general-purpose AI. The law requires developers and providers to implement safety measures, such as risk assessment and human oversight, and to provide transparent information about AI systems. It also establishes a framework for accountability, including penalties for non-compliance. The law will enter into force in August 2026, with some provisions taking effect in February 2025. The EU aims to become a global leader in AI regulation, promoting a safe and responsible digital future.
Original language: ar
Publish date: October 28, 2024 07:02 AM
Source:[@Elaph](https://elaph.com/Web/opinion/2024/10/1551754.html)

**European Union Introduces New Law to Regulate Artificial Intelligence**
The European Union has introduced a new law, (UE) 2024/1689, to regulate artificial intelligence (AI) and ensure the safety and protection of individuals and society. The law, which will come into effect in August 2026, aims to promote responsible AI development and use, while also protecting human rights and fundamental freedoms. The law defines AI as 'systems of software that use algorithms to analyze data and draw conclusions to make decisions' (Article 3). It also classifies AI systems into three categories: low-risk, high-risk, and general-purpose AI. The law requires AI developers to implement safety and security measures, including risk assessment and human oversight (Article 14). It also establishes a framework for accountability and transparency, including the obligation to provide clear information about AI systems (Article 13). The law also sets out penalties for non-compliance, including fines of up to €35 million or 7% of global annual turnover (Article 99). The law is a significant step towards creating a regulatory framework for AI in the EU, and will help to promote a safe and responsible AI ecosystem.
Original language: ar
Publish date: October 25, 2024 04:33 PM
Source:[alyaoum24.com](https://alyaoum24.com/1925347.html)

**Impact of upcoming legal changes on the use of artificial intelligence in creditworthiness assessments**
The European Union's AI Act, published on July 12, 2024, in the Official Journal of the European Union, introduces the first EU regulation on artificial intelligence. In Poland, work is underway to implement some of the AI Act's provisions through a national law and the EU's DORA regulation, which governs the use of external technology providers, including AI-based solutions, by financial institutions. In this context, attention should be drawn to the upcoming changes regarding systems of artificial intelligence used to assess creditworthiness, which are increasingly used by lenders. The new regulations classify systems used to assess creditworthiness as high-risk AI systems, as mentioned in Article 6 of the AI Act and Annex III to the regulation. The AI Act requires lenders to meet a range of obligations when using AI to assess creditworthiness, including: '...to ensure that the system is designed and developed in a way that respects the rights and freedoms of natural persons, and to ensure that the system is transparent and explainable.' Additionally, according to Article 27 of the AI Act, financial institutions will be required to conduct an assessment of the consequences of high-risk AI systems on fundamental rights and present the results to the supervisory authority. Financial institutions should also consider that the use of AI systems does not constitute a violation of the list of prohibited practices mentioned in Article 5 of the AI Act. In Poland, work has also begun on a law that will clarify some of the AI Act's provisions. As part of pre-consultations with the Ministry of Digital Affairs, the postulates of social organizations regarding the establishment of a Polish AI authority were presented, resulting in the adoption of a position on the establishment of the Artificial Intelligence Supervision Commission, which has a collegiate character and consists of representatives of other supervisory bodies. It is also worth mentioning that in Poland, work is underway on a law amending certain laws to ensure the operational digital resilience of the financial sector, ensuring the proper application of the DORA regulation, whose provisions may also apply to the use of AI systems by financial institutions. The project of the law provides for, among other things, the appointment of the Financial Supervision Commission as the supervisory body in the field of ensuring the operational digital resilience of the financial sector, as well as the introduction of changes to the law on the national cyber security system, including in the area of reporting on serious ICT incidents and cyber threats. According to the latest reports, the next version of the project is planned to be published in October.
Original language: pl
Publish date: October 24, 2024 12:50 PM
Source:[Lexology](https://www.lexology.com/library/detail.aspx?g=9c66893f-36c5-4d45-8fde-e34e9198ca7f)

**EU Establishes Strict AI Regulation to Protect Human Rights**
The European Union has established a strict regulatory framework through the IA Act, which will come into effect in August 2026 for high-risk AI systems, to protect human rights and prevent biases in AI decision-making. The regulation applies to AI systems used for candidate selection, performance evaluation, and career planning, and requires regular audits and impact assessments to prevent biases. The regulation also imposes transparency and accountability on AI system providers and deployers, and requires them to respect fundamental rights, such as avoiding discrimination and ensuring human oversight. The IA Act aims to ensure the ethical and responsible use of AI in businesses, while protecting the fundamental rights of employees. As stated by the European Union, 'the IA Act marks an important step towards AI regulation in Europe, balancing technological innovation and human rights protection.' 
Original language: fr
Publish date: October 21, 2024 01:50 PM
Source:[Le journal du net](https://www.journaldunet.com/intelligence-artificielle/1535393-les-systemes-d-ia-a-haut-risque-dans-la-gestion-des-ressources-humaines-et-du-travail-un-enjeu-critique/)

**Project Ensures Human Ownership of AI-Generated Works**
The Project of Law 2721/24 aims to alter the Copyright Law to establish that the author of a literary, artistic, or scientific work will always be a human being, regardless of the level of autonomy of the artificial intelligence system used in the creation of the work. According to Deputy Jonas Donizette, 'It is essential that the legislation follows technological changes, ensuring that the fundamental rights of creators are preserved.' The proposal recognizes the central role of humans in the creative process, even in a world increasingly influenced by artificial intelligence systems. The project will be analyzed by the committees of Science, Technology and Innovation; Culture; and Constitution and Justice and Citizenship, and will require approval in the Chamber and Senate to become a law.
Original language: pt
Publish date: October 15, 2024 12:38 PM
Source:[Portal da Câmara dos Deputados](https://www.camara.leg.br/noticias/1097441-projeto-assegura-a-humanos-titularidade-de-obras-geradas-com-inteligencia-artificial/)

**AI Competence Becomes Mandatory in 2025**
The European Union's AI Act (KI-VO) will come into effect on February 2, 2025, introducing strict training requirements and bans for AI providers and users. The goal is to increase competence in handling AI systems and harmonize the legal framework for their use. According to Article 4 of the KI-VO, providers and users of AI systems must ensure that their personnel and other individuals involved in the operation and use of AI systems have sufficient AI competence. Additionally, certain AI practices are explicitly prohibited from February 2, 2025. The KI-VO will be implemented in several phases: from February 2, 2025, certain bans and training requirements will apply, from August 2, 2026, the KI-VO will be generally applicable, and the product safety regulations will only be applicable from August 2, 2027. The KI-VO follows the general legal framework and prohibits practices such as: subtle manipulations and intentional manipulative techniques, exploiting the vulnerability of individuals, downgrading individuals based on social behavior, personal characteristics, or personality traits, deriving emotions from a natural person at work or in educational institutions, biometric categorization in sensitive areas, creating databases for facial recognition through the untargeted extraction of facial images from the internet, risk assessments for predicting future crimes based solely on profiling a natural person or evaluating their personal characteristics and properties, and using biometric real-time identification systems for law enforcement purposes, except in cases where they are necessary to prevent a concrete, significant, and immediate danger. 
Original language: de
Publish date: October 07, 2024 03:15 AM
Source:[haufe.de](https://www.haufe.de/steuern/steuerwissen-tipps/ki-vo-einheitliche-regeln-und-schulungspflichten-fuer-ki-systeme_170_633528.html)

**Many companies won't say if they'll comply with California's AI training transparency law | TechCrunch**
California's new AI training transparency law, AB-2013, requires companies to publish a summary of the data used to train their generative AI systems. However, few AI companies are willing to say whether they'll comply. TechCrunch reached out to major players in the AI space, but only Stability, Runway, and OpenAI confirmed they would comply. Microsoft declined to comment, while others remained silent. The law applies to systems released in or after January 2022, and companies have until January 2026 to begin publishing training data summaries. However, many companies are hesitant to disclose their training data, as it may reveal copyrighted or personal information, and could lead to lawsuits. Some companies, such as Meta and Google, have changed their platforms' settings to allow them to tap more user data for training, citing fair use as a defense. The outcome of AB-2013 is uncertain, and it may lead to vendors withholding certain models in California or releasing versions trained only on fair use and licensed data sets.
Original language: en
Publish date: October 04, 2024 12:31 PM
Source:[TechCrunch](https://techcrunch.com/2024/10/04/many-companies-wont-say-if-theyll-comply-with-californias-ai-training-transparency-law/)

**Many companies won’t say if they’ll comply with California’s AI training transparency law**
California's new AI training transparency law, AB-2013, requires companies to publish a summary of the data used to train their generative AI systems. However, few AI companies are willing to say whether they'll comply, with only Stability, Runway, and OpenAI confirming they will. The law applies to systems released in or after January 2022, but companies have until January 2026 to begin publishing training data summaries. The law's disclosure requirements may be problematic for vendors, as training data frequently comes from the web and may include copyrighted or personal info. Companies are citing competitive advantage and potential legal risks as reasons for nondisclosure. The law has sparked concerns about vendors withholding certain models in California or releasing versions trained only on fair use and licensed data sets.
Original language: en
Publish date: October 04, 2024 12:23 PM
Source:[latestnigeriannews.com](https://techcrunch.com/2024/10/04/many-companies-wont-say-if-theyll-comply-with-californias-ai-training-transparency-law/)

**California Passes New Generative Artificial Intelligence Law Requiring Disclosure Of Training Data**
California has passed a new law requiring developers to disclose the data used to train their generative artificial intelligence (AI) systems. The law, signed by Governor Gavin Newsom on September 28, 2024, applies to AI developers who make their systems publicly available to Californians. Developers must post documentation on their website, including the sources or owners of the datasets, a description of how the datasets further the intended purpose of the AI system or service, and other information. The law does not apply to AI systems or services whose sole purpose is to ensure security and integrity, operate aircraft, or are developed for national security, military, or defense purposes. The law goes into effect on January 1, 2026, and developers must comply by then. 'This law underscores the importance of AI developers maintaining a data provenance record that traces the lineage of data used to train AI systems and taking steps to be transparent about how they develop AI,' said the article. 'Developers should consider adopting technology that automates this process in order to operate at scale.'
Original language: en
Publish date: October 02, 2024 04:05 AM
Source:[Mondaq](https://www.mondaq.com/unitedstates/new-technology/1524792/california-passes-new-generative-artificial-intelligence-law-requiring-disclosure-of-training-data)

**European AI Regulation: Technical, Legal, Financial, Organizational, and Ethical Challenges**
The European AI Regulation, 'Technical, legal, financial, organizational, and ethical challenges', aims to regulate the use of Artificial Intelligence (AI) in various sectors. The regulation classifies AI systems into four categories based on risk: prohibited, high-risk, moderate-risk, and low-risk. Prohibited systems include those that evaluate or score behavior to determine access to services and opportunities. High-risk systems require strict compliance, including risk assessment, technical documentation, transparency, human oversight, and robustness. Moderate-risk systems must inform users that they are interacting with an AI, such as chatbots or virtual assistants. The regulation will enter into force on August 1, 2024, and will be applicable from August 2, 2026. Organizations face significant challenges in complying with the regulation, including costs, evaluation and certification, transparency and communication, data protection and privacy, innovation and competitiveness, and ethics and social responsibility. According to Eurostat, 9.2% of Spanish companies used AI technologies in 2023, above the European average of 7%.
Original language: es
Publish date: October 01, 2024 02:13 PM
Source:[Observatorio de Recursos Humanos](https://www.observatoriorh.com/opinion/reglamento-europeo-de-ia-retos-tecnicos-legales-financieros-organizativos-y-eticos.html)

**EU Chooses Experts to Develop AI Compliance Guidelines**
The European Union has chosen a group of experts in artificial intelligence to decide on the strictness with which companies will have to comply with a series of new regulations governing this technology. The EU Commission will convene the first plenary meeting of the working groups, composed of external experts, to draft the 'code of practice' of the AI law, which will specify how companies can comply with this vast set of laws. The code of practice will not be legally binding when it comes into effect in 2024, but it will provide companies with a checklist that they can use to prove that they comply with the law. Any company that claims to comply with the law while ignoring the code could face legal action. The code of practice will specify the level of detail required for companies to provide summaries of the data used to train their AI models. One of the four working groups will focus specifically on transparency and copyright issues, which could require companies to publish complete datasets, making them vulnerable to unverified legal challenges. 'The code of practice should provide a clear and practical guide for companies to ensure they comply with the AI law,' said Marietje Schaake, member of the Cyber Policy Center of Stanford University. 'It's a crucial step towards ensuring that AI is developed and used in a way that respects human rights and promotes transparency and accountability.'
Original language: fr
Publish date: September 30, 2024 02:17 PM
Source:[Boursorama](https://www.boursorama.com/bourse/actualites/l-ue-choisit-des-experts-pour-piloter-les-regles-de-conformite-en-matiere-d-ia-1ccb7bcfa0d7fb50c8bdcd7cd46bc4ed)

**California Passes New Generative Artificial Intelligence Law Requiring Disclosure of Training Data**
California has passed a new law requiring developers of generative artificial intelligence ('AI') systems to disclose the data used to train their AI. The law, signed by Governor Gavin Newsom on September 28, 2024, applies to AI developers who make their systems publicly available to Californians. The law requires developers to post information on their websites, including the sources of the datasets, how the datasets were used, and whether the datasets include personal or aggregate consumer information. The law does not apply to AI systems used for security, national airspace, or national security purposes. The law aims to increase transparency and accountability in AI development, and developers should consider adopting technology to automate this process. 'The law underscores the importance of AI developers maintaining a data provenance record that traces the lineage of data used to train AI systems,' according to the article. 'Developers should consider adopting technology that automates this process in order to operate at scale.'
Original language: en
Publish date: September 30, 2024 12:00 AM
Source:[Mayer Brown](https://mayerbrown.com/en/insights/publications/2024/09/california-passes-new-generative-artificial-intelligence-law-requiring-disclosure-of-training-data)

**Here is what's illegal under California's 18 (and counting) new AI laws**
California Governor Gavin Newsom has signed 18 new AI laws into effect, addressing pressing issues in artificial intelligence, including existential risk, deepfake nudes, and AI clones of dead performers. The laws require generative AI providers to reveal training data, disclose AI-generated content, and establish channels for users to report deepfake nudes. They also clarify that California's existing privacy laws apply to generative AI systems, and require healthcare providers to disclose when they use AI to communicate with patients. Additionally, the laws put limitations on how healthcare service providers and health insurers can automate their services, and require studios to obtain permission from actors before creating AI-generated replicas of their voice or likeness. 'Home to the majority of the world's leading AI companies, California is working to harness these transformative technologies to help address pressing challenges while studying the risks they present,' said Governor Newsom's office in a press release.
Original language: en
Publish date: September 29, 2024 10:57 PM
Source:[TechCrunch](https://techcrunch.com/2024/09/29/here-is-whats-illegal-under-californias-18-and-counting-new-ai-laws)

**EU Regulates Artificial Intelligence: 'Humans Must Always Be in Control'**
The European Union has implemented a new law regulating Artificial Intelligence (AI), which aims to ensure that humans remain in control of these technologies. According to Gabriele Mazzini, the regulation is based on the potential risk of the technology or system, with more invasive or perverse systems subject to stricter laws. For example, 'deep fakes' - videos produced with AI that depict real people but were not actually recorded - are considered a higher risk and are subject to additional regulations. Companies and systems have 36 months to adapt to the law, which is considered a horizontal regulation that affects multiple sectors of society and commerce. Mazzini, one of the authors of the AI Act, notes that the technology is not yet ready to implement the law, which is part of the European Union's new digital constitution.
Original language: pt
Publish date: September 25, 2024 07:38 PM
Source:[SAPO](https://rr.sapo.pt/noticia/pais/2024/09/25/regulamento-da-inteligencia-artificial-os-humanos-tem-de-estar-sempre-em-controlo/395012)

**New California Law Will Require AI Transparency And Disclosure Measures**
California Governor Gavin Newsom signed the California AI Transparency Act into law on September 19, 2024, which requires providers of generative artificial intelligence (AI) systems to make available AI detection tools, offer users the option to include a manifest disclosure that content is AI-generated, include a latent disclosure in AI-generated content, and enter into a contract with licensees requiring them to maintain the AI system's capability to include such a latent disclosure. The law goes into effect on January 1, 2026, and is the nation's most comprehensive and specific AI watermarking law. Covered providers will be required to comply with the law, which includes making available AI detection tools, providing users with latent and manifest disclosures, and ensuring that licensees maintain these disclosure requirements. The law will be enforced by the California Attorney General, a city attorney, or a county counsel, and provides for civil penalties of $5,000 per day if a covered provider is found to be in violation.
Original language: en
Publish date: September 25, 2024 06:07 AM
Source:[Mondaq](https://www.mondaq.com/unitedstates/new-technology/1521816/new-california-law-will-require-ai-transparency-and-disclosure-measures)

**EU Promotes Voluntary Pact on Artificial Intelligence, Excluding Meta and Apple**
More than a hundred companies, including Google, Microsoft, Open AI, and Amazon, have signed the voluntary pact promoted by the European Commission to develop artificial intelligence that respects ethical principles. However, companies like X, Meta, and Apple have not joined, and have even delayed the introduction of their AI systems in the European market due to doubts about the new EU laws regulating the sector. According to Thomas Regnier, the spokesperson for the European Commission's Market Interior, 'The pact on artificial intelligence is a voluntary instrument. Of course, we invite all companies to participate. The number will increase in the future, but it's up to private companies to make their own decisions.' The EU has also launched an industrial initiative to encourage companies to develop their AI systems. The pact will be implemented in parallel with the gradual rollout of the AI law, which will prohibit or permit the use of AI technology based on the risk it poses to people. From February, systems that categorize people based on their political, religious, philosophical, or racial beliefs, or their sexual orientation, will be prohibited. Additionally, AI systems that score people based on their behavior or personal characteristics, or those that manipulate human behavior, will also be banned. In August 2025, the criteria for transparency that AI generative systems must comply with will come into effect. These models will have to clearly indicate whether a text, song, or image has been generated through AI and ensure that the data used to train the systems respects copyright rights.
Original language: es
Publish date: September 24, 2024 11:51 PM
Source:[bitlydns.net](https://dqtjif.bitlydns.net/2024/09/25/google-y-open-ai-firman-el-pacto-de-inteligencia-artificial-de-la-ue-que-evitan-meta-o-x)

**Tech Giants Push for Lenient AI Law in Europe**
The world's largest technology companies are in a final push to influence the European Union to adopt a more lenient approach to the Artificial Intelligence (AI) Law, approved in May 2024. The new legislation aims to regulate AI comprehensively, but it is still unclear how the rules will be applied to general-purpose AI systems, such as OpenAI's ChatGPT. Companies fear that strict enforcement of the law could lead to billions of dollars in fines. The code of conduct accompanying the AI Law is being developed with the participation of companies, academics, and other stakeholders. The European Union has received over 1,000 requests to collaborate in this process, a number considered exceptionally high, according to Reuters. Boniface de Champris, senior policy manager at the commercial organization CCIA Europe, whose members include Amazon, Google, and Meta, said, 'The code of conduct is crucial. If we get it right, we can continue to innovate.' However, he also warned that if the code is too restrictive or specific, it will become very difficult. The regulation of AI raises questions about the use of data by companies like Stability AI and OpenAI to train their algorithms. The debate centers on the use of copyrighted materials without the consent of their authors, which can lead to legal disputes. To mitigate these risks, the new European legislation requires companies to disclose detailed reports on the data used to train their models. While some argue that transparency can compromise valuable commercial secrets, others claim that content creators have the right to know if their work is being used without authorization. Technology companies like Google and Amazon are also seeking to participate in the development of the code of conduct, claiming that their expertise can contribute to the effectiveness of the new rules. However, there are criticisms that these giants are trying to avoid transparency. Maximilian Gahntz, of the Mozilla Foundation, told Reuters that he believes the AI Law is an important opportunity to increase transparency in the data collection and use practices of large technology companies, revealing processes that have been unclear until now. Small European technology startups have expressed concerns that the new regulations may stifle innovation. 'We insist that these obligations need to be manageable and, if possible, adapted for startups,' said Maxime Ricard, policy manager at Allied for Startups. The code of conduct will be finalized in early 2025, and technology companies will have until August of that year to adapt to the new guidelines.
Original language: pt
Publish date: September 24, 2024 12:30 PM
Source:[IT Forum](https://itforum.com.br/noticias/gigantes-tecnologia-flexibilizar-lei-de-ia-ue)

**It's almost too late to protect our elections from AI — Congress must act now**
The 2024 general election is approaching, and artificial intelligence (AI) is already being used to create deceptive content, such as 'deepfakes', that can mislead voters. For example, AI-generated robocalls mimicking President Biden's voice told Democratic voters not to vote in the primary, and a deepfake message falsely depicted a Chicago mayoral candidate saying, 'back in my day, cops would kill 17 or 18 people and nobody would bat an eye.' These examples may soon appear amateurish as AI technology advances. To prevent electoral mischief, Congress must establish guardrails around AI use in elections. The Federal Election Commission has issued an interpretive rule, but it is inadequate to address the challenges posed by AI. New federal laws are needed to prohibit ads that fraudulently deceive and manipulate voters and require disclaimers on political ads that use AI. Congress is considering several bills, including the Protect Elections from Deceptive AI Act and the AI Transparency in Elections Act, but time is running short before the 2024 election.
Original language: en
Publish date: September 20, 2024 04:00 PM
Source:[The Hill](https://thehill.com/opinion/technology/4889200-ai-threat-deepfake-elections)

**AI-generated content could be easier to identify under new state law aimed at spotting fakes**
A new California law, signed by Gov. Gavin Newsom, requires companies with over one million monthly users to make it easier to identify AI-generated content. The law, authored by state Sen. Josh Becker, does not specify how this 'watermarking' will work technically, but rather pushes companies to develop solutions by January 1, 2026. Companies will have to offer tools for third-party developers to create their own detectors, said Becker. However, University of Chicago Assistant Professor Aloni Cohen noted that 'we don't know yet the extent to which this is technically feasible or reasonable.' Krishna Gade, CEO of Fiddler AI, said detection software will require 'significant investment' from AI companies. The law also requires companies to give users the ability to emblazon a visible watermark across AI-generated content. Newsom signed a package of AI bills, including laws requiring large social media sites to label or remove election-related deepfakes and ban unlabeled deepfakes of candidates 120 days before an election.
Original language: en
Publish date: September 20, 2024 12:50 AM
Source:[San Francisco Chronicle](http://www.sfchronicle.com/tech/article/ai-generated-content-easier-identify-new-state-law-19777954.php)

**California Governor Signs Laws to Combat 'Deepfakes' in Elections**
California Governor Gavin Newsom signed three laws on Tuesday to combat the use of artificial intelligence (AI) to create fake images or videos in political ads before the 2024 elections. A new law, which takes effect immediately, makes it illegal to create and publish 'deepfakes' related to elections 120 days before and 60 days after the electoral process. It also allows courts to stop the distribution of the materials and impose civil penalties. Newsom said, 'Protecting the integrity of elections is essential to democracy, and it's crucial that we ensure that AI is not used to undermine public trust through disinformation, especially in the current tense political climate.' The laws also require social media platforms to remove misleading content under a pioneering law that will be enacted next year. Newsom also signed a law that requires political campaigns to publicly disclose if they are publishing ads with AI-altered materials. The governor signed the laws amidst applause during a conversation with Salesforce CEO Marc Benioff at a software company event in San Francisco. The new laws reaffirm California's position as a leader in AI regulation in the US, particularly in the fight against electoral falsifications. California was the first state in the US to ban election-related videos and images in 2019. The state's technology and AI-related measures have been used as models for lawmakers across the country, said industry experts. 'There are less than 50 days to the general elections and it's urgent to protect against digitally altered and misleading content that can interfere with elections,' said Assemblywoman Gail Pellerin, author of the law that prohibits electoral falsifications. 'California is taking a stance against the manipulative use of technology to deceive voters,' she added.
Original language: es
Publish date: September 18, 2024 02:36 AM
Source:[Telemundo 52](https://www.telemundo52.com/noticias/california/california-ley-deepfakes-electorales/2691088)

**Council of Europe Adopts International Treaty on Artificial Intelligence**
The Council of Europe approved an international treaty on September 5 to ensure that artificial intelligence systems, both public and private, respect human rights, democracy, and the rule of law. This legally binding text is the first of its kind on the international stage. The treaty, titled 'Framework Convention on Artificial Intelligence, Human Rights, Democracy, and the Rule of Law', requires companies to clearly indicate whether users interact with a human or AI. It covers the entire lifecycle of AI systems, promoting innovation while reducing the risks associated with fundamental rights violations. This convention is the first international, legally binding regulation in the field of artificial intelligence. All states that adhere to it will be required to incorporate it into their national legislation. The treaty is designed to be compatible with the AI Act, a law adopted by the European Parliament in March 2024, which regulates AI systems in Europe. The treaty imposes transparency and control obligations on AI systems, making decisions taken by these systems understandable and accessible to those concerned. Users must also be informed when interacting with AI. However, exceptions are provided for reasons of national security, public order, or in the context of research and development. Emily Turrettini, a journalist specializing in new technologies, said, 'A better transparency of AI systems should allow for the identification of responsibility in case of human rights violations, and offer affected individuals the possibility to contest decisions made by these technologies.' 
Original language: fr
Publish date: September 11, 2024 09:30 AM
Source:[Bilan](https://www.bilan.ch/story/bil-opinion-emily-755650587222)

**The Risks of Artificial Intelligence in the Battlefield: A Call for Regulation**
The development of Artificial Intelligence (AI) is raising concerns about its use in the battlefield. Recently, several countries signed an international treaty on the use and standards of AI for public and private sectors. The agreement, signed by Andorra, Georgia, Iceland, Norway, Moldova, San Marino, the UK, Israel, the US, and the EU, aims to ensure that AI systems are 'totally consistent with human rights, democracy, and the rule of law.' However, the use of AI in military contexts is a different story. The development of lethal autonomous weapons systems (LAWS) has sparked debates and concerns. Although the UN's 2023 Agenda for Peace recommended that countries create a legal instrument to ban the use of autonomous lethal weapons by 2026, the current geopolitical context has hindered progress. LAWS are capable of identifying targets and engaging and destroying them autonomously, without human intervention. While semi-autonomous weapons, such as drones and missiles, are already being used in battlefields, LAWS are a different story. There is no evidence of LAWS being used in real-world conflicts, but the technology to create them is already available. This raises serious ethical, moral, and legal concerns. As Stanley Kubrick's '2001: A Space Odyssey' (1968) depicts, a machine like HAL 9000 could decide to eliminate human life. Who would be responsible for crimes of war committed by LAWS? The international community has already banned inhumane weapons, such as chemical weapons. It's time to follow this example and ban LAWS to prevent the indiscriminate use of AI as a powerful and potentially uncontrollable new military technology.
Original language: pt
Publish date: September 09, 2024 12:41 PM
Source:[Gazeta do Povo](https://www.gazetadopovo.com.br/vozes/paulo-filho/da-ficcao-a-realidade-os-riscos-da-inteligencia-artificial-no-campo-de-batalha)

*Generated by AI at [AskNews](https://asknews.app), check out the [API](https://docs.asknews.app) for more information*.
